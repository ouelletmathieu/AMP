{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/m0jnfzsj37zcnfbqpjdcj7000000gn/T/ipykernel_29151/560332721.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'NEB_binded_main' from '/Users/mathieuouellet/Dropbox/My Mac (mathieu’s MacBook Pro)/Desktop/AMP/AMP/src/polygon/NEB_binded_main.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp  # Deprecated module, consider using importlib\n",
    "import math  # Mathematical functions\n",
    "import random  # Random number generation\n",
    "import os  # Operating system interfaces\n",
    "import re  # Regular expressions\n",
    "import copy  # Object copying\n",
    "import itertools  # Iterators for efficient looping\n",
    "from collections import Counter  # Count hashable items\n",
    "from functools import cmp_to_key  # Convert old-style comparisons to key functions\n",
    "import imageio  # Image input/output\n",
    "import networkx as nx  # Graph analysis\n",
    "import csv  # CSV file reading and writing\n",
    "import subprocess  # Subprocess management\n",
    "\n",
    "from os.path import exists  # Check if a file exists\n",
    "import pickle  # Object serialization\n",
    "from os import listdir  # List directory contents\n",
    "from os.path import isfile, join  # File path operations\n",
    "import dill  # Extended pickle module\n",
    "\n",
    "import numpy as np  # Numerical computing\n",
    "from numpy import linalg as LA  # Linear algebra operations\n",
    "from shapely.geometry import Polygon, Point  # Geometric objects\n",
    "\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import matplotlib.colors as mcolors  # Color handling in matplotlib\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import pyarrow.feather as feather  # Feather format for fast data storage\n",
    "\n",
    "import manifold_util as mu  # Custom manifold utilities\n",
    "import database  # Database interaction\n",
    "import polygon_util as pu  # Polygon utilities\n",
    "import icp  # Iterative closest point algorithm\n",
    "\n",
    "import NEB_binded_main  # NEB-related module\n",
    "import NEB_main  # NEB-related module\n",
    "\n",
    "from lammps import PyLammps  # LAMMPS simulation package\n",
    "import lammps_util.Nudged_Elastic_Band as NEB  # NEB utility for LAMMPS\n",
    "import lammps_util.dynamic_file_template as dynamic_file_template  # Dynamic file templates for LAMMPS\n",
    "import lammps_util.sim_param  # Simulation parameters for LAMMPS\n",
    "import lammps_util.sim_param as sim_param  # Alias for convenience\n",
    "import lammps_util.my_lammps as mylammps  # Custom LAMMPS interface\n",
    "from lammps_util.util import Util  # Utility functions for LAMMPS\n",
    "import lammps_util.logger as logger  # Logging utilities\n",
    "import lammps_util.analysis as analysis  # Analysis tools for LAMMPS\n",
    "import lammps_util.protein_template as protein_template  # Protein templates for LAMMPS\n",
    "from lammps_util.dynamic_file_template import Save_file_full_sim  # Save file utility for LAMMPS simulations\n",
    "import lammps_util.dump as dump  # Dump file handling\n",
    "import simulation as simulation  # Simulation module\n",
    "import internal_node_main as inm  # Internal node management\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors  # Nearest neighbor search\n",
    "from scipy.stats import qmc  # Quasi-Monte Carlo sampling\n",
    "import statsmodels.stats.proportion as ssp  # Statistical proportion testing\n",
    "from scipy.interpolate import griddata  # Interpolation\n",
    "from sklearn.decomposition import PCA  # Principal Component Analysis\n",
    "\n",
    "import dumpWorker  # Worker process for dump file handling\n",
    "import multiprocessing  # Parallel processing utilities\n",
    "import dill  # Extended serialization for multiprocessing\n",
    "from multiprocessing import Pool  # Multiprocessing pool for parallel execution\n",
    "import pandas  # Data analysis\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from matplotlib import pyplot, transforms\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. **External Polygons**\n",
    "\n",
    "This section set up the database for the polygon and the simulation values.\n",
    "\n",
    "Then random polygons are added \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n=5\n",
    "db = database.Database(\"data/prion_database\")\n",
    "db.set_up_polygon(5,[1.0]*5, 5*2*math.pi/360.0, True)\n",
    "db.set_up_pairs( max_fitness_healthy=2.001, min_fitness_prion=3.0, distance_binded=0.08 , hp_pp_dif=0.2, n_point_max=5 )\n",
    "db.set_up_internal_node(nb_node_in=2, max_nb_try=200, nb_solution_wanted=1,min_avg_distance_sol=0.1 )\n",
    "db.set_up_interaction( mass=(1,1), K =(1,1) )\n",
    "db.set_up_stability(n_test_temperature=6, start_temp=0.00001, max_temp=0.01, maxtime=50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(100000):\n",
    "    db.add_polygon(pu.find_random_poly(n, 0),{\"fitness\":None}, commit=False)\n",
    "    if i %1000==0:\n",
    "        db.commit_polygon()\n",
    "db.commit_polygon()\n",
    "db.lock_polygon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a polygon with `n_create` vertices and attempt to find valid ones.\n",
    "# Each polygon is generated up to `max_try_poly * n_batch` times, depending on \n",
    "# the probability of forming a valid polygon with a minimum angle of `min_angle_poly`.\n",
    "\n",
    "n_create = 5\n",
    "max_try_poly = 1000000\n",
    "n_batch = 100\n",
    "min_angle_poly = 10*2*math.pi/360.0\n",
    "nb_try = 1000\n",
    "\n",
    "for _ in range(nb_try):\n",
    "    # Generate a set of valid conformer polygons\n",
    "    sol_set_true = pu.find_set_of_conformer_polygon(\n",
    "        [1]*n_create, max_try_poly, is_simple=True, min_angle=min_angle_poly)\n",
    "\n",
    "    for sol in sol_set_true:\n",
    "        poly1 = Polygon(sol)\n",
    "        poly2 = Polygon(sol)\n",
    "\n",
    "        # Estimate stacking using ICP with constraints on overlap and binding behavior\n",
    "        try:\n",
    "            fit_ordered, sol_ordered, output_index, intersect = pu.estimate_stacking_icp(\n",
    "                poly1, poly2, n_point_max=n_create-1, avg_dist_tol=0.3, ratio_max_overlap_area=0.02, multiple_bind=False, output_index=True)\n",
    "            print(fit_ordered[-1], sol)\n",
    "        except:\n",
    "            print(\"Error: Issue encountered during stacking estimation. Investigate further.\")\n",
    "            raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of self-binding strenght\n",
    "\n",
    "\n",
    "df = pandas.read_table(\"./data/data_n=5_self_binding_10_deg\", delimiter=';')\n",
    "columtn = df['fit']\n",
    "print(len(columtn))\n",
    "data = []\n",
    "for i in range(len(columtn)):\n",
    "    splitted = str(columtn[i]).split(\" \")\n",
    "    data.append(pu.rescale_fit(float(splitted[0])))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.hist(data, density=True, bins=30)\n",
    "plt.ylabel('%')\n",
    "plt.xlabel('binding ')\n",
    "plt.yscale('log')\n",
    "plt.savefig(f\"figure/binding_side/distrib.svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing self-matching for n in range 2 to 4\n",
    "# No solution is expected for n = 4\n",
    "\n",
    "fit_obtained = 14.50885461236566 # Precomputed fitness value\n",
    "length_obtained = [1, 1, 1, 1, 1, 1] # Edge lengths of the polygon\n",
    "# Angles defining the polygon's shape\n",
    "angles_obtained = (\n",
    "    6.187885080269032, 0.724165427552586, 2.0304603419914993,\n",
    "    3.849794768854707, 3.072941576789273, 5.179276910994469\n",
    ")\n",
    "\n",
    "# Compute the polygon's vertex positions\n",
    "pos_obtained = pu.get_pos(length_obtained, (angles_obtained, (0, 0)))[:-1]\n",
    "pos_obtained.append(pos_obtained[0]) # Close the polygon loop\n",
    "poly1 = Polygon(pos_obtained)  # Create a Polygon object\n",
    "\n",
    "\n",
    "# Check self-matching for n_to_check in [2, 3, 4]\n",
    "for n_to_check in range(2, 5):\n",
    "\n",
    "    # Attempt to find self-matching substructures within the polygon\n",
    "    found_sol = pu.check_self_matching(\n",
    "        n_to_check, poly1, avg_dist_tol=0.2, ratio_max_overlap_area=0.1)\n",
    "\n",
    "    # Plot the original polygon and any found solutions\n",
    "    for sol in found_sol:\n",
    "        for poly in [poly1, sol]:\n",
    "            x_p, y_p = poly.exterior.xy\n",
    "            plt.xlim(-10, 10)\n",
    "            plt.ylim(-10, 10)\n",
    "            plt.plot(x_p, y_p)\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and plot random polygons that fit within the specified binding range\n",
    "\n",
    "nb_to_print = 30  # Number of polygons to print\n",
    "min_bind = 3.0  # Minimum binding threshold after rescaling\n",
    "max_bind = 10000  # Maximum binding threshold after rescaling\n",
    "\n",
    "# Load self-binding data from a tab-separated file\n",
    "df = pandas.read_table(\"./data/data_n=5_self_binding_10_deg\", delimiter=';')\n",
    "\n",
    "column = df['fit']\n",
    "list_w_cond = []  # List to store selected polygons that meet the binding condition\n",
    "\n",
    "# Process each entry in the 'fit' column\n",
    "for i in range(len(column)):\n",
    "    list_part = re.split(r'\\[|\\]', column[i])  # Split to extract binding value and positions\n",
    "    fit = float(list_part[0])  # Extract and convert the fitness value\n",
    "\n",
    "    # Extract polygon vertex positions from the string\n",
    "    list_pos_xy = re.split(r'\\(|\\)', list_part[1])\n",
    "    position = [\n",
    "        tuple(float(val.replace('\\'', '')) for val in list_pos_xy[2 * i + 1].split(','))\n",
    "        for i in range(len(list_pos_xy) // 2)\n",
    "    ]\n",
    "\n",
    "    # Check if the rescaled fit value falls within the specified range\n",
    "    if min_bind < pu.rescale_fit(fit) < max_bind:\n",
    "        polygon = Polygon(position)  # Create a polygon object\n",
    "        list_w_cond.append((i, fit, polygon))\n",
    "\n",
    "# Randomly select and process `nb_to_print` polygons\n",
    "for i, fit, polygon in random.sample(list_w_cond, nb_to_print):\n",
    "\n",
    "    # Estimate stacking using ICP with specific constraints\n",
    "    fit_ordered, sol_ordered, output_index, intersect = pu.estimate_stacking_icp(\n",
    "        polygon, polygon, n_point_max=4, avg_dist_tol=0.2,\n",
    "        ratio_max_overlap_area=0.2, multiple_bind=True, output_index=True\n",
    "    )\n",
    "\n",
    "    # Print the polygon index and its fitness value\n",
    "    print(i, fit)\n",
    "\n",
    "    # Plot the original polygon and the transformed one from ICP\n",
    "    sol = sol_ordered[-1]\n",
    "    for poly in [polygon, sol]:\n",
    "        x_p, y_p = poly.exterior.xy\n",
    "        plt.xlim(-3, 3)\n",
    "        plt.ylim(-3, 3)\n",
    "        plt.plot(x_p, y_p)\n",
    "\n",
    "    # Ensure equal aspect ratio and save the figure\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(f\"figure/binding_side/{i}.svg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full manifold for a given set of solutions (external polygon shape)\n",
    "# This is purely for visualization purposes.\n",
    "\n",
    "\n",
    "dim = 3  # Arbitrary choice for visualization; does not reflect actual physical dimensions\n",
    "\n",
    "# Load the dataset containing all solutions\n",
    "df_all = pandas.read_table(\"./data/data_n=5\", delimiter=';')\n",
    "\n",
    "# Extract fitness values and corresponding polygon positions\n",
    "fit_list_all, pos_list_all = pu.read_txt_file_fit_pos(df_all)\n",
    "\n",
    "# This manifold is only used for visualization, not for structural analysis.\n",
    "full_manifold, full_manifold_pd = mu.learn_manifold(pos_list_all, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize self-binding solutions on the full manifold\n",
    "\n",
    "\n",
    "# Load dataset of self-binding solutions\n",
    "df_fitted = pandas.read_table(\"./data/data_n=5_self_binding_10_deg\", delimiter=';')\n",
    "\n",
    "# Extract fitness values and corresponding polygon positions\n",
    "fit_list_fitted, pos_list_fitted = pu.read_txt_file_fit_pos(df_fitted)\n",
    "\n",
    "angle_1,angle_2 = 60, 200\n",
    "\n",
    "# Plot the full manifold without fitness values (purely structural)\n",
    "fig, new_ax = mu.plot_manifold_3d(\n",
    "    full_manifold_pd, fitness_list=None, angle_1=angle_1, angle_2=angle_2, alpha=0.000)\n",
    "\n",
    "# Overlay self-binding solutions onto the manifold with full opacity\n",
    "fig, new_ax = mu.plot_on_manifold_3d(pos_list_fitted, full_manifold, fig=fig, active_axis=new_ax,\n",
    "                                     fitness_list=fit_list_fitted, angle_1=angle_1, angle_2=angle_2, alpha=1)\n",
    "\n",
    "fig.savefig('/Users/mathieuouellet/Desktop/AMP/Figures/n_5_manifold_binding.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. **Pair Selection for Prion Formation**\n",
    "\n",
    "Now that we have tested some of the functions for generating polygons and checked whether they match, we can take the next step: **creating a database** and applying the same methods on a larger scale.  \n",
    "\n",
    "By storing polygons in a structured database, we can systematically search for **healthy-prion pairs** and analyze their transformations more efficiently.  \n",
    "\n",
    "To achieve this, we will use the script **`polygon_matching_main.py`**, which handles both polygon matching and database operations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The script  polygon_matching_main.py identifies and selects polygonal structures that could act as potential prion candidates based on their binding properties. It compares **healthy** and **prion** structures to find pairs that satisfy specific geometric and binding conditions. The goal is to determine whether a **healthy** structure can transition into a **prion** while maintaining its binding interactions.\n",
    "\n",
    "1. **Load Data**  \n",
    "   - Retrieve polygonal structures from the database.\n",
    "   - Separate structures into *healthy* and *prion* candidates.\n",
    "  \n",
    "2. **Compute Binding Properties**  \n",
    "   - Determine how strongly prions bind to themselves.\n",
    "   - Evaluate how well healthy structures bind to prions.\n",
    "\n",
    "3. **Filter Based on Selection Criteria**  \n",
    "   A pair *(healthy, prion)* is considered valid if it meets the following conditions:\n",
    "\n",
    "   - **COND1:** The healthy structure binds less than a maximum threshold.\n",
    "   - **COND2:** The prion binds more than a minimum threshold.\n",
    "   - **COND3:** The fitness of the *(healthy, prion)* binding is significantly lower than the *(prion, prion)* binding.\n",
    "   - **COND4:** The fitness of the *(healthy, prion)* binding is at least as high as the *(healthy, healthy)* binding.\n",
    "   - **COND5:** The healthy and prion structures must bind to the same sites on the prion.\n",
    "   - **COND6:** The healthy structure must be able to morph into the prion while remaining bound.\n",
    "\n",
    "4. **Store Valid Pairs in the Database**  \n",
    "   - If a valid transition is found, the pair is recorded for further analysis.\n",
    "   - Previously tested pairs are also stored to avoid redundant computations.\n",
    "\n",
    "**Usage**\n",
    "Run the script with:\n",
    "\n",
    "```bash\n",
    "python polygon_matching_main.py\n",
    "```\n",
    "\n",
    "The database path must be manually modified in the main section of the script:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "   db = database.Database(\"src/polygon/data/n=5_5deg_2\")  # Change this path to your database location\n",
    "   select_pairs(db)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data base and set the parameter the next algorithm will use\n",
    "\n",
    "\n",
    "db = database.Database(\"/Users/mathieuouellet/Desktop/n=5_5deg_2\")\n",
    "\n",
    "db.set_up_polygon(5, [1.0]*5, 5*2*math.pi/360.0, True)\n",
    "db.set_up_pairs(max_fitness_healthy=2.001, min_fitness_prion=3.0,\n",
    "                distance_binded=0.08, hp_pp_dif=0.2, n_point_max=5)\n",
    "db.set_up_internal_node(nb_node_in=2, max_nb_try=200,\n",
    "                        nb_solution_wanted=1, min_avg_distance_sol=0.1)\n",
    "db.set_up_interaction(mass=(1, 1), K=(1, 1))\n",
    "db.set_up_stability(n_test_temperature=6, start_temp=0.00001,\n",
    "                    max_temp=0.01, maxtime=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. **Internal nodes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `internal_node_main.py` script is responsible for generating, comparing, and validating internal node configurations for polygon-based structures. The script integrates MATLAB to optimize internal node placements while ensuring they meet connectivity constraints.\n",
    "\n",
    "### **Key Functions**\n",
    "#### **1. `start_matlab_engine()`**  \n",
    "\n",
    "- Initializes the MATLAB engine and adds the required MATLAB scripts to the path.\n",
    "- Returns an active MATLAB engine instance.\n",
    "\n",
    "#### **2. `get_random_conn(n_out, nedge, npoint)`**  \n",
    "- Generates a random connection between internal and external nodes while ensuring all nodes are connected.\n",
    "- Uses random partitioning of edges to create connectivity groups.\n",
    "- Ensures each node is part of a valid connection structure.\n",
    "- Returns a list of connection groups.\n",
    "\n",
    "#### **3. `compare_connection(connection1, connection2)`**  \n",
    "- Compares two connection configurations to determine if they are equivalent.\n",
    "- Uses permutations to check all possible mappings of internal nodes.\n",
    "- Returns a boolean indicating equivalence and mapping information if they match.\n",
    "\n",
    "#### **4. `compare_distance(inside_node_1, inside_node_2, perm)`**  \n",
    "- Computes the average Euclidean distance between corresponding internal nodes.\n",
    "- Used to check the similarity of two internal node configurations after mapping.\n",
    "- Returns the average distance.\n",
    "\n",
    "\n",
    "#### **5. `find_solution(db, eng, list_key_dict=None, nb_solution_wanted=None, max_nb_try=None, min_avg_distance_sol=None, nb_node_in=None, conn_func=None)`**\n",
    "- Core function that iterates over database entries to find valid internal node configurations.\n",
    "- Uses the MATLAB engine to optimize node placements.\n",
    "- Ensures uniqueness of solutions before adding them to the database.\n",
    "- Handles locking/unlocking of database entries to prevent conflicts in multi-threaded environments.\n",
    "- Saves valid configurations to the database.\n",
    "\n",
    "## Usage\n",
    "The script can be executed directly, with user-defined parameters to control the search space. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell counts the number of solutions stored in the database and identifies which external polygons successfully match with a prion partner. It tracks how these matches are stored and calculates the total number of solutions and the ratio of successful pairings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load solution found and count them \n",
    "\n",
    "total_sol, total_not_sol = 0, 0  \n",
    "potential_key_pairs = []  # List to store key pairs with solutions\n",
    "total_hp, total_hp_not = 0, 0  # Counters for healthy-prion pairs with and without solutions\n",
    "\n",
    "# Iterate through all healthy keys in the database\n",
    "for key_h in list(db.db_pairs):\n",
    "\n",
    "    # Iterate through all prion keys associated with the healthy key\n",
    "    for key_p in db.db_pairs[key_h].keys():\n",
    "\n",
    "        # Check if there are solutions for this (healthy, prion) pair\n",
    "        if 'sols' in db.db_pairs[key_h][key_p]:\n",
    "            total_hp += 1  # Increment count of pairs with solutions\n",
    "            potential_key_pairs.append((key_h, key_p))  # Store the key pair\n",
    "\n",
    "            # Count the number of solutions for this pair\n",
    "            total_sol += len(list(db.db_pairs[key_h][key_p]['sols']))\n",
    "        else:\n",
    "            total_hp_not += 1  # Increment count of pairs without solutions\n",
    "\n",
    "# Print total number of healthy-prion pairs with solutions and their ratio to those without solutions\n",
    "print(total_hp, total_hp / total_hp_not if total_hp_not != 0 else \"N/A\")  \n",
    "\n",
    "# Print total number of solutions found\n",
    "print(total_sol)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. **NEB Computation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nudged Elastic Band (NEB) Simulation for Polygon Transitions**\n",
    "\n",
    "This script performs **Nudged Elastic Band (NEB) simulations** to analyze how a **healthy polygon** transitions into a **prion-like structure** under physical constraints. The goal is to compute **reaction pathways**, **binding energies**, and **morphological transformations** between these structures.\n",
    "\n",
    "### **Key Functions**\n",
    "#### **1. `create_executable()`**  \n",
    "Generates an executable script for running **LAMMPS** simulations using MPI across multiple nodes.\n",
    "\n",
    "#### **2. `_get_energy()`**  \n",
    "Computes the energy of a given **protein configuration** based on bond stretching.\n",
    "\n",
    "#### **3. `get_energy()`**  \n",
    "Extracts NEB simulation data and calculates energy values for each intermediate structure.\n",
    "\n",
    "#### **4. `get_NEB()`**  \n",
    "Runs the **NEB simulation** for a given **(healthy, prion) pair** and stores the computed reaction coordinates and energy landscape.\n",
    "\n",
    "#### **5. `neb_fill_database()`**  \n",
    "Fills the database with **NEB results** by iterating through all healthy-prion pairs and storing computed **energy profiles** and **reaction coordinates**.\n",
    "\n",
    "### **Workflow**\n",
    "1. **Load the database** containing healthy and prion structures.\n",
    "2. **Select polygon pairs** for which NEB simulations will be performed.\n",
    "3. **Run LAMMPS simulations** to compute energy barriers and binding dynamics.\n",
    "4. **Store results** in the database for further analysis.\n",
    "\n",
    "### **Usage**\n",
    "Run the script with:\n",
    "\n",
    "```bash\n",
    "python neb_simulation.py\n",
    "```\n",
    "Alternatively, you can specify a subset of polygon pairs to compute:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NEB_binded_main.py: Handling the Bonded Case**\n",
    "\n",
    "The script **`NEB_binded_main.py`** operates similarly to **`neb_simulation.py`**, but it specifically handles cases where the **healthy and prion structures remain bonded during the transition**.  \n",
    "\n",
    "It follows the same workflow—loading the database, selecting pairs, running **Nudged Elastic Band (NEB) simulations**, and storing results—but ensures that binding constraints are maintained throughout the process.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#        load energy list and reaction coordinate H<->P        #\n",
    "################################################################\n",
    "\n",
    "\n",
    "nb_plotted = 0\n",
    "rms_list = []\n",
    "energy_list = []\n",
    "temp_list = []\n",
    "stab_list_h = []\n",
    "stab_list_p = []\n",
    "rc_coor_list = []\n",
    "bind_coor_list = []\n",
    "bind_energy_list = []\n",
    "bind_pos_list = []\n",
    "bind_angle_list = []\n",
    "\n",
    "healthy_key = []\n",
    "prion_key = []\n",
    "sol_key = []\n",
    "\n",
    "for key_h in list(db.db_pairs):\n",
    "\n",
    "    for key_p in db.db_pairs[key_h].keys():\n",
    "        if 'sols' in db.db_pairs[key_h][key_p]:\n",
    "            for key_s in db.db_pairs[key_h][key_p]['sols'].keys():\n",
    "\n",
    "                if type(db.db_pairs[key_h][key_p]['sols'][key_s]) != int:\n",
    "\n",
    "                    reaction_coordinate = None\n",
    "                    energy = None\n",
    "                    RMS_hp = None\n",
    "                    temperature_list = None\n",
    "                    healthy_angle_list = None\n",
    "                    prion_angle_list = None\n",
    "                    binded_reaction_coordinate = None\n",
    "                    binded_energy = None\n",
    "                    binded_pos_list = None\n",
    "                    binded_angle_list = None\n",
    "\n",
    "                    if 'NEB_HP_energy' in db.db_pairs[key_h][key_p]['sols'][key_s]:\n",
    "                        reaction_coordinate = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_reaction_coordinate']\n",
    "                        energy = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_energy']\n",
    "\n",
    "                    if 'RMS_hp' in db.db_pairs[key_h][key_p]['sols'][key_s]:\n",
    "                        RMS_hp = db.db_pairs[key_h][key_p]['sols'][key_s]['RMS_hp']\n",
    "                        temperature_list = db.db_pairs[key_h][key_p]['sols'][key_s]['RMS_stability_temp']\n",
    "                        healthy_angle_list = [\n",
    "                            x/RMS_hp for x in db.db_pairs[key_h][key_p]['sols'][key_s]['RMS_stability_healthy']]\n",
    "                        prion_angle_list = [\n",
    "                            x/RMS_hp for x in db.db_pairs[key_h][key_p]['sols'][key_s]['RMS_stability_prion']]\n",
    "\n",
    "                    if 'NEB_HP_PP_energy' in db.db_pairs[key_h][key_p]['sols'][key_s]:\n",
    "\n",
    "                        binded_reaction_coordinate = db.db_pairs[key_h][key_p][\n",
    "                            'sols'][key_s]['NEB_HP_PP_reaction_coordinate']\n",
    "                        binded_energy = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_PP_energy']\n",
    "\n",
    "                    if 'NEB_HP_PP_pos_list' in db.db_pairs[key_h][key_p]['sols'][key_s]:\n",
    "                        binded_pos_list = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_PP_pos_list']\n",
    "                        binded_angle_list = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_PP_angle_list']\n",
    "\n",
    "                    nb_plotted += 1\n",
    "                    rms_list.append(RMS_hp)\n",
    "                    energy_list.append(energy)\n",
    "                    temp_list.append(temperature_list)\n",
    "                    stab_list_h.append(healthy_angle_list)\n",
    "                    stab_list_p.append(prion_angle_list)\n",
    "                    rc_coor_list.append(reaction_coordinate)\n",
    "                    bind_coor_list.append(binded_reaction_coordinate)\n",
    "                    bind_energy_list.append(binded_energy)\n",
    "                    bind_pos_list.append(binded_pos_list)\n",
    "                    bind_angle_list.append(binded_angle_list)\n",
    "                    healthy_key.append(key_h)\n",
    "                    prion_key.append(key_p)\n",
    "                    sol_key.append(key_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_from_key(key_healthy, key_prion, key_sol):\n",
    "\n",
    "    protein_pair = db.load_protein_pair(key_healthy, key_prion, key_sol)\n",
    "\n",
    "    healthy_pos = protein_pair.healthy_position\n",
    "    prion_pos = protein_pair.prion_position\n",
    "    connection = protein_pair.connection\n",
    "\n",
    "    min_x = min(min(x[1] for x in prion_pos), min(x[1] for x in healthy_pos))\n",
    "    max_x = max(max(x[1] for x in prion_pos), max(x[1] for x in healthy_pos))\n",
    "    min_y = min(min(x[2] for x in prion_pos), min(x[2] for x in healthy_pos))\n",
    "    max_y = max(max(x[2] for x in prion_pos), max(x[2] for x in healthy_pos))\n",
    "\n",
    "\n",
    "    fig, (ax1,ax2) = plt.subplots(1, 2,figsize=(8, 12), dpi=80)\n",
    "    ax1.set_xlim(min_x-0.05, max_x+0.05)\n",
    "    ax1.set_ylim(min_y-0.05, max_y+0.05)\n",
    "    ax2.set_xlim(min_x-0.05, max_x+0.05)\n",
    "    ax2.set_ylim(min_y-0.05, max_y+0.05)\n",
    "    ax1.set_aspect('equal', adjustable='box')\n",
    "    ax2.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    #plot\n",
    "    for conn in connection:\n",
    "        i, j = conn[0],conn[1]\n",
    "        xl, yl = [prion_pos[i][1],prion_pos[j][1]], [prion_pos[i][2],prion_pos[j][2]]\n",
    "        ax1.plot(xl, yl)\n",
    "        xl, yl = [healthy_pos[i][1],healthy_pos[j][1]], [healthy_pos[i][2],healthy_pos[j][2]]\n",
    "        ax2.plot(xl, yl)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def max_none(e, min_e, max_e):\n",
    "    if e is not None:\n",
    "        m = max(e)\n",
    "        if m>min_e and m<max_e:\n",
    "            return m\n",
    "    \n",
    "        return None\n",
    "def min_capped(min_val, val):\n",
    "    return min_val if val < min_val else val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "#                Plot of the activation energy                 #\n",
    "################################################################\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6), dpi=120)\n",
    "\n",
    "for i in range(len(energy_list)):\n",
    "    if energy_list[i] is not None and max(energy_list[i]) < 0.1:\n",
    "        energy_capped = [min_capped(1e-5, e) for e in energy_list[i]]\n",
    "\n",
    "        plt.plot(rc_coor_list[i], energy_capped, c='b', alpha=0.01)\n",
    "\n",
    "\n",
    "plt.xlabel(\"reaction coordinate (arbitrary unit) \")\n",
    "plt.ylabel(\"energy (arbitrary unit)\")\n",
    "\n",
    "fig.savefig('/Users/mathieuouellet/Desktop/AMP/Figures/rc_e_all.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#         PLOT ENERGY H-P vs HP-PP          #\n",
    "#############################################\n",
    "\n",
    "\n",
    "min_e, max_e = 1E-8, 1E0\n",
    "\n",
    "log_e_list = [max_none(e, min_e, max_e ) for e in energy_list]\n",
    "log_binded_e = [max_none(e, min_e, max_e ) for e in bind_energy_list]\n",
    "\n",
    "tot = sum(item is not None for item in log_binded_e)\n",
    "print(tot)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6), dpi=120)\n",
    "plt.plot(log_e_list, log_binded_e, 'o', alpha=0.1)\n",
    "plt.xlabel(\"maximum energy H<->P transition (arbitrary unit) \")\n",
    "plt.ylabel(\"maximum energy HP<->PP transition (arbitrary unit)\")\n",
    "plt.ylim((1e-4, 1e-1))\n",
    "plt.xlim((1e-4, 1e-1))\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "fig.savefig(\n",
    "    '/Users/mathieuouellet/Desktop/AMP/Figures/H_stability_log_e_HP_vs_HPPP_transition.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = database.Database(\"/Users/mathieuouellet/Desktop/n=5_5deg_2_good\")\n",
    "list_potential_key = []\n",
    "\n",
    "found = False\n",
    "key_pairs = list(db.db_pairs.keys())\n",
    "for k_h in key_pairs:\n",
    "    keys_prion = list(db.db_pairs[k_h].keys())\n",
    "    for k_p in keys_prion:\n",
    "        if 'sols' in db.db_pairs[k_h][k_p] and len(db.db_pairs[k_h][k_p]['sols'].keys()) > 1:\n",
    "            \n",
    "            first_key = list(db.db_pairs[k_h][k_p]['sols'].keys())[0]\n",
    "            list_potential_key.append((k_h, k_p, first_key))\n",
    "            found += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef make_binded():\\n\\n    k_h, k_p, k_s = list_potential_key[2]\\n\\n    pos_h = db.db_pairs[k_h][\\'struct_healthy\\']\\n    pos_p = db.db_pairs[k_h][k_p][\\'struct\\']\\n    translation = db.db_pairs[k_h][k_p][\\'translation\\']\\n    binded_hp = db.db_pairs[k_h][k_p][\\'binded_hp\\']\\n    inside_node = db.db_pairs[k_h][k_p][\\'sols\\'][k_s][\\'inside_node\\']\\n    conn = db.db_pairs[k_h][k_p][\\'sols\\'][k_s][\\'conn\\']\\n    n_out = len(pos_h)-1\\n    # load properties\\n    target_previous_pp_fitness = db.db_pairs[k_h][k_p][\\'pp_fitness\\']\\n    target_previous_hp_fitness = db.db_pairs[k_h][k_p][\\'hp_fitness\\']\\n    n_point_max = db.db_parameter[\"n_point_max\"]\\n    min_r_squared_default = db.min_r_squared_default\\n\\n    # TODO add a check for no multi bind\\n    assert count_binding(binded_hp) == 1, \"multiple binding\"\\n\\n    # correct connection (fit the indices and not matlab)\\n    conn = [(c[0]-1, c[1]) for c in conn]\\n\\n    # get back the binding PH and the binding PP\\n    healthy_poly, prion_poly = Polygon(pos_h), Polygon(pos_p)\\n    fit_ordered_hp, sol_ordered_hp, output_index_hp, _ = pu.estimate_stacking_icp(\\n        healthy_poly, prion_poly, avg_dist_tol=0.3, n_point_max=n_point_max,  multiple_bind=False, output_index=True)\\n    hp_fit_max = pu.rescale_fit(fit_ordered_hp[-1], min_r_squared_default)\\n    fit_ordered_pp, sol_ordered_pp, output_index_pp, _ = pu.estimate_stacking_icp(\\n        prion_poly, prion_poly, avg_dist_tol=0.3, n_point_max=n_point_max,  multiple_bind=False, output_index=True)\\n    pp_fit_max = pu.rescale_fit(fit_ordered_pp[-1], min_r_squared_default)\\n\\n    # todo assert if they are kinda the same\\n    assert (hp_fit_max-target_previous_hp_fitness) < 0.01, \"there is a big difference in the fitness\" +         str(hp_fit_max-target_previous_hp_fitness)\\n    assert (pp_fit_max-target_previous_pp_fitness) < 0.01, \"there is a big difference in the fitness\" +         str(pp_fit_max-target_previous_pp_fitness)\\n\\n    # get position with inside node for prion / healthy\\n    all_h, all_p = add_center_node(pos_h, pos_p, inside_node)\\n    full_healthy_hp, full_prion_pp_p2 = np.copy(all_h), np.copy(all_p)\\n\\n    # get binded node from the prion that do not move\\n    healthy_binded, prion_binded = [p[0]\\n                                    for p in binded_hp], [p[1] for p in binded_hp]\\n    init_prion_3 = [list(prion_poly.exterior.coords)[i] for i in prion_binded]\\n    # transform the inside point by refitting the subset of bonded point for HP\\n    sol_hp_3 = [list(sol_ordered_hp[-1].exterior.coords)[i]\\n                for i in prion_binded]\\n    full_prion_hp, trans_hp = transform_all_point_back(\\n        sol_hp_3, init_prion_3, sol_ordered_hp[-1], all_p, False)\\n    # transform the inside point by refitting the subset of bonded point for PP\\n    sol_pp_3 = [list(sol_ordered_pp[-1].exterior.coords)[i]\\n                for i in prion_binded]\\n    full_prion_pp_p1, trans_pp = transform_all_point_back(\\n        sol_pp_3, init_prion_3, sol_ordered_pp[-1], all_p, False)\\n\\n    # set un the dict for the nodes\\n    binded_translated = {translation[p[0]]: p[1] for p in binded_hp}\\n    dict_hp = get_dict_node(full_healthy_hp, full_prion_hp,\\n                            binded_hp, n_out, translation)\\n    dict_edge_hp = get_dict_edge(\\n        full_healthy_hp, dict_hp, binded_translated, conn, n_out, translation)\\n\\n    # set un the dict for the nodes\\n    identity_translation = {i: i for i in range(n_out)}\\n    binded_pp = [(translation[p[0]], p[1]) for p in binded_hp]\\n    dict_pp = get_dict_node(\\n        full_prion_pp_p2, full_prion_pp_p1, binded_pp, n_out, identity_translation)\\n    dict_edge_pp = get_dict_edge(\\n        full_prion_pp_p2, dict_pp, binded_translated, conn, n_out, identity_translation)\\n\\n    assert set(dict_edge_pp.keys()) == set(\\n        dict_edge_hp.keys()), \"edge set should be the same\"\\n    assert set(dict_pp.keys()) == set(\\n        dict_hp.keys()), \"node set should be the same\"\\n\\n    protein_pair, dict_pos_in_protein = create_protein_pair(\\n        dict_hp, dict_pp, dict_edge_pp, n_out)\\n\\n    pos_bottom, pos_top = get_position_healthy_prion(\\n        protein_pair.prion_position, dict_pos_in_protein, binded_translated, len(all_h), n_out)\\n    print(len(protein_pair.prion_position))\\n    print(binded_hp)\\n    print(dict_pos_in_protein)\\n    # print(protein_pair.prion_position)\\n    # print(pos_bottom)\\n    # print(pos_top)\\n\\n    print(\"HP\")\\n    plot(dict_hp, dict_edge_hp, n_out)\\n    plt.show()\\n    print(\"PP\")\\n    plot(dict_pp, dict_edge_pp, n_out)\\n    plt.show()\\n    print(\"top\")\\n    ax1 = plt.subplot()\\n    plt.plot([p[0] for p in pos_top], [p[1] for p in pos_top], \\'o\\')\\n    for i in range(len(pos_top)):\\n        p = pos_top[i]\\n        ax1.annotate(str(i), (p[0], p[1]), color=\\'green\\')\\n    plt.show()\\n    print(\"down\")\\n    ax1 = plt.subplot()\\n    plt.plot([p[0] for p in pos_bottom], [p[1] for p in pos_bottom], \\'o\\')\\n    for i in range(len(pos_bottom)):\\n        p = pos_bottom[i]\\n        ax1.annotate(str(i), (p[0], p[1]), color=\\'green\\')\\n\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_dist(list_pos, np_array_pos):\n",
    "\n",
    "    return sum(math.sqrt((list_pos[i][0] - np_array_pos[i, 0]) ** 2 + (list_pos[i][1] - np_array_pos[i, 1]) ** 2) for i in range(len(list_pos)))\n",
    "\n",
    "\n",
    "def get_distance(pos1, pos2):\n",
    "    return math.sqrt((pos1[0]-pos2[0])**2 + (pos1[1]-pos2[1])**2)\n",
    "\n",
    "\n",
    "def add_center_node(pos_h, pos_p, inside_node):\n",
    "    pos_p_2 = (copy.copy(pos_p))\n",
    "    pos_p_2.extend(list(zip(inside_node[2], inside_node[3])))\n",
    "    all_p = np.array(pos_p_2)\n",
    "\n",
    "    # get position with inside node for healthy\n",
    "    pos_h_2 = (copy.copy(pos_h))\n",
    "    pos_h_2.extend(list(zip(inside_node[0], inside_node[1])))\n",
    "    all_h = np.array(pos_h_2)\n",
    "\n",
    "    return all_h, all_p\n",
    "\n",
    "\n",
    "def add_edge(dict_edge, dict_node, key1, key2, node_pos, binded, n_out):\n",
    "\n",
    "    if key1[0] == n_out:\n",
    "        key1 = (0, key1[1])\n",
    "    if key2[0] == n_out:\n",
    "        key2 = (0, key2[1])\n",
    "\n",
    "    # if none of them were deleted\n",
    "    if key1 in dict_node and key2 in dict_node:\n",
    "        dict_edge[(key1, key2)] = get_distance(\n",
    "            node_pos[key1[0]], node_pos[key2[0]])\n",
    "    else:\n",
    "        if key1 not in dict_node and key2 in dict_node:\n",
    "            dict_edge[((binded[key1[0] % n_out], 'p'), key2)] = get_distance(\n",
    "                node_pos[key1[0] % n_out], node_pos[key2[0]])\n",
    "        if key1 in dict_node and key2 not in dict_node:\n",
    "            dict_edge[(key1, (binded[key2[0] % n_out], 'p'))] = get_distance(\n",
    "                node_pos[key1[0]], node_pos[key2[0] % n_out])\n",
    "\n",
    "\n",
    "def translate_position(non_translated_pos, translation):\n",
    "\n",
    "    translated_pos = [0]*len(non_translated_pos)\n",
    "    for i in range(len(non_translated_pos)):\n",
    "        if i in translation:\n",
    "            translated_pos[i] = (\n",
    "                non_translated_pos[translation[i], 0], non_translated_pos[translation[i], 1])\n",
    "        else:\n",
    "            translated_pos[i] = (non_translated_pos[i, 0],\n",
    "                                 non_translated_pos[i, 1])\n",
    "\n",
    "    return translated_pos\n",
    "\n",
    "\n",
    "def transform_all_point_back(binded_from_sol, binded_to_move, solution_poly, full_point_to_transform, inverse):\n",
    "    # transform the inside point by refitting the subset of bonded point for HP\n",
    "    trans1_hp, data1_hp, trans2_hp, data2_hp = pu.find_good_initial_guess(\n",
    "        set_pt1=binded_from_sol, set_pt2=binded_to_move, data_to_shift=full_point_to_transform)\n",
    "    dist1_hp, dist2_hp = avg_dist(list(solution_poly.exterior.coords), data1_hp), avg_dist(\n",
    "        list(solution_poly.exterior.coords), data2_hp)\n",
    "    if not inverse:\n",
    "        full_point_transformed, tr = data1_hp, trans1_hp\n",
    "        if dist2_hp < dist1_hp:\n",
    "            full_point_transformed, tr = data2_hp, trans2_hp\n",
    "    else:\n",
    "        full_point_transformed, tr = data2_hp, trans1_hp\n",
    "        if dist2_hp < dist1_hp:\n",
    "            full_point_transformed, tr = data1_hp, trans2_hp\n",
    "\n",
    "    return full_point_transformed, tr\n",
    "\n",
    "\n",
    "def get_dict_node(full_bottom_node, full_top_node, binded_pairs_list, n_out, translation):\n",
    "    # set un the dict for the nodes\n",
    "    dict_node_temp, dict_node = {}, {}\n",
    "    for i in range(len(full_bottom_node)):\n",
    "        dict_node_temp[(i, 'h')] = full_bottom_node[i]\n",
    "    for i in range(len(full_top_node)):\n",
    "        dict_node_temp[(i, 'p')] = full_top_node[i]\n",
    "    # remove the loop\n",
    "    del dict_node_temp[(n_out, 'h')]\n",
    "    del dict_node_temp[(n_out, 'p')]\n",
    "    # remvove healty binding\n",
    "    for p in binded_pairs_list:\n",
    "        del dict_node_temp[(p[0], 'h')]\n",
    "\n",
    "    # translate the healthy and put in new dict\n",
    "    for i in range(len(full_bottom_node)):\n",
    "        if (i, 'h') in dict_node_temp:\n",
    "            if i in translation:\n",
    "                dict_node[(translation[i], 'h')] = dict_node_temp[(i, 'h')]\n",
    "            else:\n",
    "                dict_node[(i, 'h')] = dict_node_temp[(i, 'h')]\n",
    "        if (i, 'p') in dict_node_temp:\n",
    "            dict_node[(i, 'p')] = dict_node_temp[(i, 'p')]\n",
    "    return dict_node\n",
    "\n",
    "\n",
    "def get_dict_edge(full_bottom_node, dict_node, binded_dict, connection,  n_out, translation):\n",
    "\n",
    "    # get edge list\n",
    "    dict_edge = {}\n",
    "    # translate the healthy of hp to fit pp\n",
    "    full_healthy_hp_translated = translate_position(\n",
    "        full_bottom_node, translation)\n",
    "    # put the outside edge for both\n",
    "    for i in range(n_out+1):\n",
    "        # get the position of the two consecutive edge of the outside\n",
    "        key1, key2 = (i, 'h'), ((i+1) % n_out, 'h')\n",
    "        add_edge(dict_edge, dict_node, key1, key2,\n",
    "                 full_healthy_hp_translated, binded_dict, n_out)\n",
    "        # the second protein doesn't have any edge removed therefore we can add them all\n",
    "        key1p, key2p = (i, 'p'), ((i+1) % n_out, 'p')\n",
    "        add_edge(dict_edge, dict_node, key1p, key2p,\n",
    "                 full_healthy_hp_translated, binded_dict,  n_out)\n",
    "\n",
    "    # edge to the inside\n",
    "    for p in connection:\n",
    "        f_, t_ = p[0], p[1]\n",
    "        # for the botom protein some edge are removed so we need to check\n",
    "        key1, key2 = (f_, 'h'), (t_, 'h')\n",
    "        add_edge(dict_edge, dict_node, key1, key2,\n",
    "                 full_healthy_hp_translated, binded_dict, n_out)\n",
    "        # for the top one no edge are removed\n",
    "        key1p, key2p = (f_, 'p'), (t_, 'p')\n",
    "        add_edge(dict_edge, dict_node, key1p, key2p,\n",
    "                 full_healthy_hp_translated, binded_dict, n_out)\n",
    "\n",
    "    return dict_edge\n",
    "\n",
    "\n",
    "def count_binding(binding_list):\n",
    "    count_1 = Counter([p[0] for p in binding_list])\n",
    "    count_2 = Counter([p[1] for p in binding_list])\n",
    "    return max([max(list(count_1.values())), max(list(count_2.values()))])\n",
    "\n",
    "\n",
    "def plot(node_dict: dict, edge_dict: dict, n_out):\n",
    "    for edg, dist in edge_dict.items():\n",
    "        start = node_dict[edg[0]]\n",
    "        end = node_dict[edg[1]]\n",
    "        if edg[0][0] < n_out and edg[1][0] < n_out:\n",
    "            plt.plot([start[0], end[0]], [start[1], end[1]], c=\"black\")\n",
    "        else:\n",
    "            plt.plot([start[0], end[0]], [start[1], end[1]], c=\"red\")\n",
    "\n",
    "\n",
    "def plot_test(pos_h, pos_p):\n",
    "    x_h, y_h, l_h = [p[0] for p in pos_h], [p[1]\n",
    "                                            for p in pos_h], [str(i) for i in range(len(pos_h))]\n",
    "    x_p, y_p, l_p = [p[0] for p in pos_p], [p[1]\n",
    "                                            for p in pos_p], [str(i) for i in range(len(pos_p))]\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    plt.plot(x_h, y_h, 'o', c='g')\n",
    "    plt.plot(x_p, y_p, 'o', c='r')\n",
    "    for i in range(len(x_h)):\n",
    "        ax1.annotate(l_h[i], (x_h[i]+0.1, y_h[i]+0.1), color='green')\n",
    "        ax1.annotate(l_p[i], (x_p[i]+0.05, y_p[i]+0.05), color='red')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_protein_pair(dict_hp, dict_pp, dict_edge_pp, n_out):\n",
    "\n",
    "    protein_pair = protein_template.Protein_Template()\n",
    "    dict_hp_key = list(dict_hp.keys())\n",
    "\n",
    "    healthy_pos_protein_format, prion_pos_protein_format = [], []\n",
    "    dict_pos_in_protein = {}\n",
    "\n",
    "    # translate_healthy_position\n",
    "    for i, key in enumerate(dict_hp_key):\n",
    "        typ = 1  # inside node\n",
    "        if key[0] <= n_out:\n",
    "            typ = 0  # outside node\n",
    "        pos_hp, pos_pp = dict_hp[key], dict_pp[key]\n",
    "        dict_pos_in_protein[key] = i\n",
    "        healthy_pos_protein_format.append([typ, pos_hp[0], pos_hp[1]])\n",
    "        prion_pos_protein_format.append([typ, pos_pp[0], pos_pp[1]])\n",
    "\n",
    "    conn_protein_format, conn_length_list = [], []\n",
    "\n",
    "    # define all the edges/interaction\n",
    "    for key in dict_edge_pp:\n",
    "        from_id = dict_pos_in_protein[key[0]]\n",
    "        to_id = dict_pos_in_protein[key[1]]\n",
    "        conn_protein_format.append([from_id, to_id])\n",
    "        conn_length_list.append(dict_edge_pp[key])\n",
    "\n",
    "    # format in numpy array\n",
    "    healthy_pos_protein_format = np.array(healthy_pos_protein_format)\n",
    "    prion_pos_protein_format = np.array(prion_pos_protein_format)\n",
    "    conn_protein_format = np.array(conn_protein_format)\n",
    "\n",
    "    # create the protein template\n",
    "    protein_pair.set_healthy_structure(\n",
    "        position=healthy_pos_protein_format, connection=conn_protein_format)\n",
    "    protein_pair.set_prion_structure(position=prion_pos_protein_format)\n",
    "    protein_pair.set_bond_length(conn_length_list)\n",
    "\n",
    "    return protein_pair, dict_pos_in_protein\n",
    "\n",
    "\n",
    "def get_position_healthy_prion(all_position, dict_pos_in_protein, binded_pp, n_node, n_out):\n",
    "    pos_bottom, pos_top = [], []\n",
    "\n",
    "    for i in range(n_node+1):\n",
    "        if i != n_out:  # remove the node that was previously used to close the outside polygon\n",
    "\n",
    "            if (i, 'h') in dict_pos_in_protein:\n",
    "                pos = all_position[dict_pos_in_protein[(i, 'h')]]\n",
    "            else:\n",
    "                pos = all_position[dict_pos_in_protein[(\n",
    "                    binded_pp[i % n_out], 'p')]]\n",
    "                print((binded_pp[i % n_out], 'p'))\n",
    "            pos_bottom.append([pos[1], pos[2]])\n",
    "            if (i, 'p') in dict_pos_in_protein:\n",
    "                pos = all_position[dict_pos_in_protein[(i, 'p')]]\n",
    "                pos_top.append([pos[1], pos[2]])\n",
    "\n",
    "    return pos_bottom, pos_top\n",
    "\n",
    "def euclid2(vec1, vec2):\n",
    "    return(math.sqrt((vec1[0]-vec2[0])**2 +(vec1[1]-vec2[1])**2) )\n",
    "\n",
    "\n",
    "\n",
    "def make_binded():\n",
    "\n",
    "    k_h, k_p, k_s = list_potential_key[2]\n",
    "\n",
    "    pos_h = db.db_pairs[k_h]['struct_healthy']\n",
    "    pos_p = db.db_pairs[k_h][k_p]['struct']\n",
    "    translation = db.db_pairs[k_h][k_p]['translation']\n",
    "    binded_hp = db.db_pairs[k_h][k_p]['binded_hp']\n",
    "    inside_node = db.db_pairs[k_h][k_p]['sols'][k_s]['inside_node']\n",
    "    conn = db.db_pairs[k_h][k_p]['sols'][k_s]['conn']\n",
    "    n_out = len(pos_h)-1\n",
    "    # load properties\n",
    "    target_previous_pp_fitness = db.db_pairs[k_h][k_p]['pp_fitness']\n",
    "    target_previous_hp_fitness = db.db_pairs[k_h][k_p]['hp_fitness']\n",
    "    n_point_max = db.db_parameter[\"n_point_max\"]\n",
    "    min_r_squared_default = db.min_r_squared_default\n",
    "\n",
    "    # TODO add a check for no multi bind\n",
    "    assert count_binding(binded_hp) == 1, \"multiple binding\"\n",
    "\n",
    "    # correct connection (fit the indices and not matlab)\n",
    "    conn = [(c[0]-1, c[1]) for c in conn]\n",
    "\n",
    "    # get back the binding PH and the binding PP\n",
    "    healthy_poly, prion_poly = Polygon(pos_h), Polygon(pos_p)\n",
    "    fit_ordered_hp, sol_ordered_hp, output_index_hp, _ = pu.estimate_stacking_icp(\n",
    "        healthy_poly, prion_poly, avg_dist_tol=0.3, n_point_max=n_point_max,  multiple_bind=False, output_index=True)\n",
    "    hp_fit_max = pu.rescale_fit(fit_ordered_hp[-1], min_r_squared_default)\n",
    "    fit_ordered_pp, sol_ordered_pp, output_index_pp, _ = pu.estimate_stacking_icp(\n",
    "        prion_poly, prion_poly, avg_dist_tol=0.3, n_point_max=n_point_max,  multiple_bind=False, output_index=True)\n",
    "    pp_fit_max = pu.rescale_fit(fit_ordered_pp[-1], min_r_squared_default)\n",
    "\n",
    "    # todo assert if they are kinda the same\n",
    "    assert (hp_fit_max-target_previous_hp_fitness) < 0.01, \"there is a big difference in the fitness\" + \\\n",
    "        str(hp_fit_max-target_previous_hp_fitness)\n",
    "    assert (pp_fit_max-target_previous_pp_fitness) < 0.01, \"there is a big difference in the fitness\" + \\\n",
    "        str(pp_fit_max-target_previous_pp_fitness)\n",
    "\n",
    "    # get position with inside node for prion / healthy\n",
    "    all_h, all_p = add_center_node(pos_h, pos_p, inside_node)\n",
    "    full_healthy_hp, full_prion_pp_p2 = np.copy(all_h), np.copy(all_p)\n",
    "\n",
    "    # get binded node from the prion that do not move\n",
    "    healthy_binded, prion_binded = [p[0]\n",
    "                                    for p in binded_hp], [p[1] for p in binded_hp]\n",
    "    init_prion_3 = [list(prion_poly.exterior.coords)[i] for i in prion_binded]\n",
    "    # transform the inside point by refitting the subset of bonded point for HP\n",
    "    sol_hp_3 = [list(sol_ordered_hp[-1].exterior.coords)[i]\n",
    "                for i in prion_binded]\n",
    "    full_prion_hp, trans_hp = transform_all_point_back(\n",
    "        sol_hp_3, init_prion_3, sol_ordered_hp[-1], all_p, False)\n",
    "    # transform the inside point by refitting the subset of bonded point for PP\n",
    "    sol_pp_3 = [list(sol_ordered_pp[-1].exterior.coords)[i]\n",
    "                for i in prion_binded]\n",
    "    full_prion_pp_p1, trans_pp = transform_all_point_back(\n",
    "        sol_pp_3, init_prion_3, sol_ordered_pp[-1], all_p, False)\n",
    "\n",
    "    # set un the dict for the nodes\n",
    "    binded_translated = {translation[p[0]]: p[1] for p in binded_hp}\n",
    "    dict_hp = get_dict_node(full_healthy_hp, full_prion_hp,\n",
    "                            binded_hp, n_out, translation)\n",
    "    dict_edge_hp = get_dict_edge(\n",
    "        full_healthy_hp, dict_hp, binded_translated, conn, n_out, translation)\n",
    "\n",
    "    # set un the dict for the nodes\n",
    "    identity_translation = {i: i for i in range(n_out)}\n",
    "    binded_pp = [(translation[p[0]], p[1]) for p in binded_hp]\n",
    "    dict_pp = get_dict_node(\n",
    "        full_prion_pp_p2, full_prion_pp_p1, binded_pp, n_out, identity_translation)\n",
    "    dict_edge_pp = get_dict_edge(\n",
    "        full_prion_pp_p2, dict_pp, binded_translated, conn, n_out, identity_translation)\n",
    "\n",
    "    assert set(dict_edge_pp.keys()) == set(\n",
    "        dict_edge_hp.keys()), \"edge set should be the same\"\n",
    "    assert set(dict_pp.keys()) == set(\n",
    "        dict_hp.keys()), \"node set should be the same\"\n",
    "\n",
    "    protein_pair, dict_pos_in_protein = create_protein_pair(\n",
    "        dict_hp, dict_pp, dict_edge_pp, n_out)\n",
    "\n",
    "    pos_bottom, pos_top = get_position_healthy_prion(\n",
    "        protein_pair.prion_position, dict_pos_in_protein, binded_translated, len(all_h), n_out)\n",
    "    print(len(protein_pair.prion_position))\n",
    "    print(binded_hp)\n",
    "    print(dict_pos_in_protein)\n",
    "    # print(protein_pair.prion_position)\n",
    "    # print(pos_bottom)\n",
    "    # print(pos_top)\n",
    "\n",
    "    print(\"HP\")\n",
    "    plot(dict_hp, dict_edge_hp, n_out)\n",
    "    plt.show()\n",
    "    print(\"PP\")\n",
    "    plot(dict_pp, dict_edge_pp, n_out)\n",
    "    plt.show()\n",
    "    print(\"top\")\n",
    "    ax1 = plt.subplot()\n",
    "    plt.plot([p[0] for p in pos_top], [p[1] for p in pos_top], 'o')\n",
    "    for i in range(len(pos_top)):\n",
    "        p = pos_top[i]\n",
    "        ax1.annotate(str(i), (p[0], p[1]), color='green')\n",
    "    plt.show()\n",
    "    print(\"down\")\n",
    "    ax1 = plt.subplot()\n",
    "    plt.plot([p[0] for p in pos_bottom], [p[1] for p in pos_bottom], 'o')\n",
    "    for i in range(len(pos_bottom)):\n",
    "        p = pos_bottom[i]\n",
    "        ax1.annotate(str(i), (p[0], p[1]), color='green')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_markov(conf_mol_list_list, multiple_conf_list = False):\n",
    "    count_init = [0]*3\n",
    "    transtition = np.zeros((3,3))\n",
    "    precision = 0.00001\n",
    "    max_time_markov = 1000000\n",
    "\n",
    "    if not multiple_conf_list:\n",
    "        conf_mol_list_list =[conf_mol_list_list]\n",
    "  \n",
    "    for conf_mol_list in conf_mol_list_list:\n",
    "        for mol_id in range(len(conf_mol_list[0])):\n",
    "\n",
    "            conf_list = [conf[mol_id] for conf in conf_mol_list]\n",
    "\n",
    "            for i in range(len(conf_list)-1):\n",
    "                count_init[conf_list[i]]+=1\n",
    "                transtition[conf_list[i],conf_list[i+1]]+=1\n",
    "\n",
    "    for i, j in itertools.product(range(3), range(3)):\n",
    "        if count_init[i]!=0:\n",
    "            transtition[i,j]=transtition[i,j]/count_init[i]\n",
    "        else:\n",
    "            transtition[i,i] = 1\n",
    "\n",
    "\n",
    "    transtition = np.transpose(transtition)\n",
    "    initial_state = np.array( [[1],[0],[0]])\n",
    "    active_state = initial_state\n",
    "\n",
    "    list_prion,list_healthy,list_other = [], [], []\n",
    "    list_healthy.append(active_state[0,0])\n",
    "    list_prion.append(active_state[1,0])\n",
    "    list_other.append(active_state[2,0])\n",
    "\n",
    "    t_react = 0\n",
    "    for t in range(max_time_markov):\n",
    "        active_state = np.dot(transtition,active_state)\n",
    "        list_healthy.append(active_state[0,0])\n",
    "        list_prion.append(active_state[1,0])\n",
    "        list_other.append(active_state[2,0])\n",
    "        delta = abs(list_prion[-1]-list_prion[-2]) + abs(list_healthy[-1]-list_healthy[-2]) + abs(list_other[-1]-list_other[-2])\n",
    "        if precision > delta :\n",
    "            t_react = t\n",
    "            break\n",
    "    \n",
    "\n",
    "    return list_healthy[-1], list_prion[-1], list_other[-1], t_react, np.transpose(transtition)\n",
    "\n",
    "def get_markov_confidence_2x2(transtition2x2, ratio_uncertainty):\n",
    "\n",
    "\n",
    "    a = transtition2x2[1,0] #rate_h_to_p\n",
    "    b = transtition2x2[0,1] #rate_p_to_h\n",
    "    if a==0 and b==0:\n",
    "        return 0,0,0\n",
    "        \n",
    "    error = ratio_uncertainty* (2*a*b) /((a + b)**2) \n",
    "    \n",
    "    return   a/(a+b), error\n",
    "    \n",
    "\n",
    "\n",
    "def get_markov_confidence(conf_mol_list, n_sim):\n",
    "    count_init = [0]*3\n",
    "    transtition_star = np.zeros((3,3))\n",
    "    precision = 0.00001\n",
    "    max_time_markov = 1000000\n",
    "\n",
    "    for mol_id in range(len(conf_mol_list[0])):\n",
    "\n",
    "        conf_list = [conf[mol_id] for conf in conf_mol_list]\n",
    "\n",
    "        for i in range(len(conf_list)-1):\n",
    "            count_init[conf_list[i]]+=1\n",
    "            transtition_star[conf_list[i],conf_list[i+1]]+=1\n",
    "\n",
    "    list_all_healthy, list_all_prion, list_all_other, list_all_t_react = [], [], [], []\n",
    "\n",
    "    #for each simulation\n",
    "    for _ in range(n_sim):\n",
    "        \n",
    "        #create a matrix \n",
    "        transtition_interval = np.zeros((3,3))\n",
    "        for row in range(3):\n",
    "            prop_star = [transtition_star[row,j] for j in range(3)]\n",
    "            if prop_star[0]!=0 and prop_star[1]!=0 and prop_star[2]!=0:\n",
    "                confint = ssp.multinomial_proportions_confint(counts=prop_star, alpha=0.05)\n",
    "                new_count = [confint[i,0]+(confint[i,1]-confint[i,0])*random.random() for i in range(3)]\n",
    "                new_count = [c/sum(new_count) for c in new_count]\n",
    "                #print(row, transtition_star[row], new_count)\n",
    "                \n",
    "            elif sum(prop_star)!=0:\n",
    "                new_count = [c/sum(prop_star) for c in prop_star]\n",
    "            else:\n",
    "                new_count = [0,0,0]\n",
    "                new_count[row]=1.0\n",
    "            for col in range(3):\n",
    "                    transtition_interval[row,col]=new_count[col]\n",
    "\n",
    "        transtition = np.transpose(transtition_interval)\n",
    "        initial_state = np.array( [[1],[0],[0]])\n",
    "        active_state = initial_state\n",
    "\n",
    "        list_prion,list_healthy,list_other = [], [], []\n",
    "        list_healthy.append(active_state[0,0])\n",
    "        list_prion.append(active_state[1,0])\n",
    "        list_other.append(active_state[2,0])\n",
    "\n",
    "        t_react = 0\n",
    "        for t in range(max_time_markov):\n",
    "            active_state = np.dot(transtition,active_state)\n",
    "            list_healthy.append(active_state[0,0])\n",
    "            list_prion.append(active_state[1,0])\n",
    "            list_other.append(active_state[2,0])\n",
    "            delta = abs(list_prion[-1]-list_prion[-2]) + abs(list_healthy[-1]-list_healthy[-2]) + abs(list_other[-1]-list_other[-2])\n",
    "            if precision > delta :\n",
    "                t_react = t\n",
    "                break\n",
    "        \n",
    "        list_all_healthy.append(list_healthy[-1])\n",
    "        list_all_prion.append(list_prion[-1])\n",
    "        list_all_other.append(list_other[-1])\n",
    "        list_all_t_react.append(t_react)\n",
    "\n",
    "              \n",
    "    #set the star transition again\n",
    "    for i, j in itertools.product(range(3), range(3)):\n",
    "        if count_init[i]!=0:\n",
    "            transtition_star[i,j]=transtition_star[i,j]/count_init[i]\n",
    "        else:\n",
    "            transtition_star[i,i] = 1\n",
    "\n",
    "    return list_all_healthy, list_all_prion, list_all_other, list_all_t_react,  np.transpose(transtition_star)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. **Dynamical Simulation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation and Protein Binding Documentation\n",
    "\n",
    "### Overview\n",
    "This script is designed to handle simulations involving protein binding and molecular interactions using LAMMPS. It generates, transforms, and evaluates protein structures within a defined computational framework. The script includes functionalities for molecule insertion, energy minimization, and dynamic simulation using LAMMPS and mathematical utilities.\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "#### 1. `get_protein_pairs_binded_divided_bypass()`\n",
    "- Transforms and aligns protein structures while maintaining binding constraints.\n",
    "- Returns transformed protein configurations with updated molecular positions.\n",
    "\n",
    "#### 2. `get_protein_pairs_binded_divided()`\n",
    "- Computes protein structure alignments and fitness scores.\n",
    "- Ensures that healthy and prion protein structures are correctly matched.\n",
    "- Returns transformed protein positions with connectivity data.\n",
    "\n",
    "#### 3. `set_up_molecule_simulation()`\n",
    "- Initializes a LAMMPS simulation with specified molecular configurations.\n",
    "- Defines interaction parameters such as bond types, Lennard-Jones potentials, and simulation boundaries.\n",
    "- Ensures compatibility with molecular binding constraints.\n",
    "\n",
    "#### 4. `insert_avoiding_molecule()`\n",
    "- Places molecules into a simulation box while avoiding overlap.\n",
    "- Uses quasi-random sampling for uniform distribution.\n",
    "- Assigns molecules to appropriate groups for simulation tracking.\n",
    "\n",
    "#### 5. `insert_avoiding_binded_molecule()`\n",
    "- Similar to `insert_avoiding_molecule()` but ensures molecular pairs remain bound during placement.\n",
    "- Introduces relative translations between molecule pairs.\n",
    "\n",
    "#### 6. `simulate_HP()`\n",
    "- Runs a LAMMPS simulation on healthy and prion binded structures.\n",
    "- Logs molecular interactions and connectivity over time.\n",
    "- Generates output files and optionally produces visualization GIFs.\n",
    "\n",
    "#### 7. `simulate()`\n",
    "- Iterates over a temperature range to perform multiple simulations.\n",
    "- Stores results for healthy and binded protein states.\n",
    "- Saves all computed values for further analysis.\n",
    "\n",
    "### Usage\n",
    "The script is typically executed with user-defined parameters. Example:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    path = \"path/to/database\"\n",
    "    db = database.Database(path)\n",
    "    key_ps_pair = None  # Simulate all solutions\n",
    "    list_temp = None  # Use standard temperature range\n",
    "    sim_param = None  # Default simulation parameters\n",
    "    \n",
    "    for key_h, key_p, key_s in key_ps_pair:\n",
    "        worker_id = os.getpid()\n",
    "        simulate(db, worker_id, (key_h, key_p, key_s),\n",
    "                 num=NB_TEMP,\n",
    "                 temperature_min=MIN_TEMP,\n",
    "                 temperature_max=MAX_TEMP,\n",
    "                 PRE=PRE,\n",
    "                 is_PP=False,\n",
    "                 temperature_list=list_temp,\n",
    "                 sim_param=sim_param)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the Markov analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prion_property(temp_list, p_list, temp_list_H, p_list_H, o_list_H):\n",
    "\n",
    "    min_p_healthy = 0.05 #healthy should not become prion\n",
    "    min_o_binded = 0.05 #side product should not be produced \n",
    "\n",
    "    list1 = [t for i,t in enumerate(temp_list_H) if p_list_H[i]< min_p_healthy]\n",
    "    list2 = [t for i,t in enumerate(temp_list_H) if o_list_H[i]< min_o_binded]\n",
    "\n",
    "    max_p, id_p = -1, -1\n",
    "\n",
    "    if len(list1)*len(list2)>0:\n",
    "        sep_p_0 = max(list1)\n",
    "        bound_o_0 = max(list2)\n",
    "        bound_t = min(sep_p_0,bound_o_0)\n",
    "\n",
    "        for i,t in enumerate(temp_list):\n",
    "            if p_list[i]>=max_p and t<=bound_t:\n",
    "                id_p=i\n",
    "                max_p=p_list[i]\n",
    "\n",
    "    return (temp_list[id_p],max_p) if id_p!=-1 else (None, None)\n",
    "\n",
    "\n",
    "\n",
    "def get_conformation_from_saved(path, saved=None, binded_dict=None, nonbinded_dict=None):\n",
    "    \n",
    "    if saved is None:\n",
    "        saved = Save_file_full_sim.load(path)\n",
    "\n",
    "    if binded_dict is None :\n",
    "        binded_dict = {}\n",
    "        nonbinded_dict = {}\n",
    "\n",
    "    print(saved.key)\n",
    "    key_saved = saved.key\n",
    "    \n",
    "    #get time where we start to loose non-binded-healthy \n",
    "    for i in range(len(saved.temp_list_H)):\n",
    "        #print(len(saved.count_list_H[i]))\n",
    "        if len(saved.count_list_H[i])==8:\n",
    "            count_healthy_H, count_prion_H, count_other_H, count_healthy_even_H, count_prion_even_H, count_other_even_H, conf_mol_list_H, distance_list_H  = saved.count_list_H[i]\n",
    "        else:\n",
    "            count_healthy_H, count_prion_H, count_other_H, count_healthy_even_H, count_prion_even_H, count_other_even_H, conf_mol_list_H  = saved.count_list_H[i]\n",
    "            distance_list_H=None\n",
    "        \n",
    "        temp = saved.temp_list_H[i]\n",
    "        if temp not in nonbinded_dict:\n",
    "            nonbinded_dict[temp] = []\n",
    "        nonbinded_dict[temp].append(conf_mol_list_H)\n",
    "\n",
    "\n",
    "    #get time where we start to loose binded-healthy \n",
    "    for i in range(len(saved.temp_list)):\n",
    "\n",
    "        if len(saved.count_list[i])==8:\n",
    "            count_healthy, count_prion, count_other, count_healthy_even, count_prion_even, count_other_even, conf_mol_list, distance_list = saved.count_list[i]\n",
    "        else:\n",
    "            count_healthy, count_prion, count_other, count_healthy_even, count_prion_even, count_other_even, conf_mol_list = saved.count_list[i]\n",
    "            distance_list = None\n",
    "\n",
    "        temp = saved.temp_list[i]\n",
    "        if temp not in binded_dict:\n",
    "            binded_dict[temp] = []\n",
    "        binded_dict[temp].append(conf_mol_list)\n",
    "    \n",
    "    return nonbinded_dict, binded_dict\n",
    "\n",
    "def merge_dict(dict1, dict2):\n",
    "    for key in dict2.keys():\n",
    "        if key not in dict1:\n",
    "            dict1[key] = []\n",
    "        dict1[key].extend(dict2[key])\n",
    "\n",
    "def get_markov_binned(conformation_dict, temperature_range):\n",
    "\n",
    "    conformation_dict_binned = {i:[] for i in range(len(temperature_range))}\n",
    "    t_list, p_list, o_list, h_list  = [],[],[],[]\n",
    "    rate_diff = []\n",
    "\n",
    "\n",
    "\n",
    "    for temp in conformation_dict:\n",
    "        for conf_list in conformation_dict[temp]:\n",
    "\n",
    "            dist, best_t_ind = 10000000000,  0\n",
    "            for t_ind in range(len(temperature_range)):\n",
    "                if abs(temp-temperature_range[t_ind]) < dist:\n",
    "                    dist = abs(temp-temperature_range[t_ind])\n",
    "                    best_t_ind = t_ind\n",
    "                \n",
    "            \n",
    "            conformation_dict_binned[best_t_ind].append(conf_list)\n",
    "\n",
    "    for t_ind in range(len(temperature_range)):\n",
    "\n",
    "        if len(conformation_dict_binned[t_ind]) > 0:\n",
    "            h,p,o,t_react, t_mat = get_markov(conformation_dict_binned[t_ind], multiple_conf_list=True)\n",
    "            val,error = get_markov_confidence_2x2(np.transpose(t_mat), 0.5)\n",
    "\n",
    "            t_list.append(temperature_range[t_ind])\n",
    "            h_list.append(h)\n",
    "            p_list.append(p)\n",
    "            o_list.append(o)\n",
    "            rate_diff.append([val,error ])#t_mat[0,1] - t_mat[1,0])\n",
    "\n",
    "    return t_list, h_list, p_list, o_list, rate_diff\n",
    "    \n",
    "\n",
    "def plot_binded(db, key_selected, ax):\n",
    "    \n",
    "    k_h, k_p, k_s = key_selected\n",
    "    pos_h = db.db_pairs[k_h]['struct_healthy']\n",
    "    pos_p = db.db_pairs[k_h][k_p]['struct']\n",
    "    translation = db.db_pairs[k_h][k_p]['translation']\n",
    "    binded_hp = db.db_pairs[k_h][k_p]['binded_hp']\n",
    "    inside_node = db.db_pairs[k_h][k_p]['sols'][k_s]['inside_node']\n",
    "    conn = db.db_pairs[k_h][k_p]['sols'][k_s]['conn']\n",
    "    n_out = len(pos_h)-1\n",
    "    # load properties\n",
    "    target_previous_pp_fitness = db.db_pairs[k_h][k_p]['pp_fitness']\n",
    "    target_previous_hp_fitness = db.db_pairs[k_h][k_p]['hp_fitness']\n",
    "    n_point_max = db.db_parameter[\"n_point_max\"]\n",
    "    min_r_squared_default = db.min_r_squared_default\n",
    "\n",
    "    \n",
    "\n",
    "    if not 'hp_fit_dic' in  db.db_pairs[k_h][k_p].keys() :\n",
    "\n",
    "        full_healthy_hp, full_prion_hp, prion_binded, full_prion_pp_p1 = simulation.get_protein_pairs_binded_divided(pos_h, pos_p, binded_hp, inside_node, translation, target_previous_pp_fitness, target_previous_hp_fitness, min_r_squared_default, n_point_max, n_out)\n",
    "\n",
    "    else:\n",
    "        hp_fit_dic = db.db_pairs[k_h][k_p]['hp_fit_dic']\n",
    "        pp_fit_dic = db.db_pairs[k_h][k_p]['pp_fit_dic']\n",
    "        hp_vec = hp_fit_dic['sol_ordered_hp'][-1], hp_fit_dic['binded_hp']\n",
    "        pp_vec = pp_fit_dic['sol_ordered_pp'][-1], pp_fit_dic['binded_pp']\n",
    "        full_healthy_hp, full_prion_hp, prion_binded, full_prion_pp_p1 = simulation.get_protein_pairs_binded_divided_bypass(pos_h, pos_p, translation, inside_node, conn=[], hp_vec=hp_vec, pp_vec=pp_vec, n_out=len(pos_h)-1, translated=False )\n",
    "\n",
    "\n",
    "    all_conn = [(p[0]-1,p[1]-1) for p in conn] + [(i,i+1) for i in range(n_out-1)] + [(n_out-1,0)]\n",
    "    all_conn = np.array(all_conn)\n",
    "    \n",
    "    protein_pair = protein_template.Protein_Template()\n",
    "    protein_pair.set_prion_structure(full_prion_hp, connection = all_conn)\n",
    "    protein_pair.set_healthy_structure(full_healthy_hp)\n",
    "    protein_pair.plot(ax)\n",
    "\n",
    "    return protein_pair\n",
    "\n",
    "def get_neb_pos_list(vec_out, zero_on = 0, rotate_on = 1):\n",
    "    \n",
    "    pos_h_x = [[p-v[0][zero_on] for p in v[0]] for v in vec_out]\n",
    "    pos_h_y = [[p-v[1][zero_on] for p in v[1]] for v in vec_out]\n",
    "    pos_list = []\n",
    "\n",
    "    for frame in range(len(pos_h_x)):\n",
    "        theta = math.atan2(pos_h_y[frame][rotate_on], pos_h_x[frame][rotate_on])\n",
    "        c, s = np.cos(-theta), np.sin(-theta)\n",
    "        R = np.array(((c, -s), (s, c)))\n",
    "        pos_array = [ np.dot(R,np.array([x,y])) for x,y in zip(pos_h_x[frame],pos_h_y[frame]) ] \n",
    "        pos_array = [ np.dot(np.array([[1.0/pos_array[rotate_on][0],0],[0,1.0/pos_array[rotate_on][0]]]),arr) for arr in pos_array]\n",
    "        pos_list.append([v[0] for v in pos_array] + [v[1] for v in pos_array])\n",
    "\n",
    "    return np.array(pos_list)\n",
    "\n",
    "def _translate(all_pos, dict_pos_in_protein, binded_translated, n_unbind, n_out):\n",
    "\n",
    "    list_pos_top = []\n",
    "    list_pos_bottom = []\n",
    "\n",
    "    for j in range(len(all_pos)):\n",
    "\n",
    "\n",
    "\n",
    "        pos_bottom, pos_top = NEB.get_position_healthy_prion(\n",
    "            [[all_pos[j][0][i], all_pos[j][1][i]] for i in range(len(all_pos[j][0]))], dict_pos_in_protein, binded_translated, n_unbind, n_out)\n",
    "        \n",
    "        pos_top = list(zip(*pos_top))\n",
    "        pos_bottom = list(zip(*pos_bottom))\n",
    "\n",
    "        list_pos_top.append(pos_top)\n",
    "        list_pos_bottom.append(pos_bottom)\n",
    "\n",
    "    return  list_pos_bottom, list_pos_top\n",
    "\n",
    "def get_translation_binded_function_neb(db, key_healthy, key_prion, key_sol):\n",
    "\n",
    "    value_dict = NEB_binded_main.load_value(db, None, key_healthy, key_prion, key_sol)\n",
    "\n",
    "    n_out = len(value_dict[\"pos_h\"])-1\n",
    "    # load the protein\n",
    "    protein_pair_unbinded = db.load_protein_pair(\n",
    "        key_healthy, key_prion, key_sol)\n",
    "        \n",
    "    if not 'hp_fit_dic' in  db.db_pairs[key_healthy][key_prion].keys():\n",
    "        protein_pair_binded, dict_pos_in_protein, (in_edge,out_edge)  = NEB.get_protein_pairs_binded(value_dict[\"pos_h\"], value_dict[\"pos_p\"], value_dict[\"translation\"], binded_hp=value_dict[\"binded_hp\"], inside_node=value_dict[\"inside_node\"], conn=value_dict[\"conn\"], target_previous_pp_fitness=value_dict[\"target_previous_pp_fitness\"],\n",
    "                                                                            target_previous_hp_fitness=value_dict[\"target_previous_hp_fitness\"], min_r_squared_default=value_dict[\"min_r_squared_default\"], n_point_max=value_dict[\"n_point_max\"])\n",
    "    else:\n",
    "        print(\"bypass in angle\")\n",
    "        hp_fit_dic = db.db_pairs[key_healthy][key_prion]['hp_fit_dic']\n",
    "        pp_fit_dic = db.db_pairs[key_healthy][key_prion]['pp_fit_dic']\n",
    "        hp_vec = hp_fit_dic['sol_ordered_hp'][-1], hp_fit_dic['binded_hp']\n",
    "        pp_vec = pp_fit_dic['sol_ordered_pp'][-1], pp_fit_dic['binded_pp']\n",
    "        protein_pair_binded, dict_pos_in_protein, edges = NEB.get_protein_pairs_binded_bypass(value_dict[\"pos_h\"], value_dict[\"pos_p\"], value_dict[\"translation\"], inside_node=value_dict[\"inside_node\"], conn=value_dict[\"conn\"], hp_vec=hp_vec, pp_vec=pp_vec)\n",
    "    \n",
    "    \n",
    "    # get translation\n",
    "    binded_translated = {\n",
    "        value_dict[\"translation\"][p[0]]: p[1] for p in value_dict[\"binded_hp\"]}\n",
    "\n",
    "    pos_unbind = [[], []]\n",
    "    for i in range(len(protein_pair_unbinded.healthy_position)):\n",
    "        pos = protein_pair_unbinded.healthy_position[i]\n",
    "        pos_unbind[0].append([pos[1], pos[2]])\n",
    "        pos = protein_pair_unbinded.prion_position[i]\n",
    "        pos_unbind[1].append([pos[1], pos[2]])\n",
    "    \n",
    "    trans_func = partial(_translate, dict_pos_in_protein=dict_pos_in_protein, binded_translated=binded_translated, n_unbind=len(protein_pair_unbinded.prion_position), n_out=n_out)\n",
    "\n",
    "    return  trans_func\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot transition between structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gif(energy_list : list[float], conn_all, pos_all, energy_all, box, gif_name : str,  list_of_plot : list[dict] = [],  speed_up_zero = 4):\n",
    "    # sourcery no-metrics skip: default-mutable-arg\n",
    "\n",
    "    conn_in, conn_out = conn_all\n",
    "    in_pos, out_pos = pos_all\n",
    "    in_energy_length, out_energy_length = energy_all\n",
    "\n",
    "\n",
    "    cmap  = plt.get_cmap('cividis')\n",
    "    max_energy = max(energy_list)\n",
    "    \n",
    "    filenames = []\n",
    "    selector = [0]*len(energy_list)\n",
    "    for i in range(len(energy_list)):\n",
    "        if energy_list[i] < 0.01 * max(energy_list) and i > 0:\n",
    "            selector[i] = selector[i-1]+1\n",
    "\n",
    "\n",
    "    for i in range(len(energy_list)):\n",
    "        \n",
    "        #if select \n",
    "        if selector[i]==0 or selector[i]%speed_up_zero==0 or i==len(energy_list)-1:\n",
    "            height_fig = 3 + len(list_of_plot) + 1 \n",
    "            height_ratio = [1]*(len(list_of_plot)+1) + [3]\n",
    "\n",
    "            fig, ax_list = plt.subplots(len(list_of_plot)+2, 1,figsize=(8, height_fig*3), dpi=300, gridspec_kw={'height_ratios': height_ratio})\n",
    "\n",
    "            ax_list[-1].set_xlim(box[0]-0.05, box[1]+0.05)\n",
    "            ax_list[-1].set_ylim(box[2]-0.05, box[3]+0.05)\n",
    "            ax_list[-1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "            for j in range(len(conn_out)):\n",
    "                xl, yl = out_pos[i][j]\n",
    "                ener = out_energy_length[i][j]\n",
    "                ax_list[-1].plot(xl, yl, c=cmap(ener/max_energy))\n",
    "\n",
    "            for j in range(len(conn_in)):\n",
    "                break\n",
    "                xl, yl = in_pos[i][j]\n",
    "                ener = in_energy_length[i][j]\n",
    "                ax_list[-1].plot(xl, yl, c=cmap(ener/max_energy))\n",
    "\n",
    "            #plot energy\n",
    "            xl = [k/len(energy_list) for k in range(i+1) ]\n",
    "            yl = energy_list[:i+1]\n",
    "            ax_list[0].plot(xl,yl, linewidth=3, label = 'average bead')\n",
    "            ax_list[0].set_xlim((0,1))\n",
    "            ax_list[0].set_ylim((0,1.2*max_energy))\n",
    "            ax_list[0].set_xlabel(\"reaction coordinate\")\n",
    "            ax_list[0].set_ylabel(\"energy\")\n",
    "\n",
    "\n",
    "\n",
    "            #plot the rest\n",
    "            for i_p, to_plot in enumerate(list_of_plot):\n",
    "                min_y, max_y = 1E100, -1E100\n",
    "                \n",
    "                for yl_full, lab in zip(to_plot[\"ys\"], to_plot[\"labels\"]) : \n",
    "\n",
    "                    xl = [k/len(energy_list) for k in range(i+1) ]\n",
    "                    yl = yl_full[:i+1]\n",
    "                    ax_list[i_p+1].plot(xl,yl, linewidth=3, label = lab)\n",
    "                    if min(yl_full)<min_y:\n",
    "                        min_y= min(yl_full)\n",
    "                    if max(yl_full)>max_y:\n",
    "                        max_y = max(yl_full)\n",
    "                    \n",
    "                ax_list[i_p+1].set_xlim((0,1))\n",
    "                ax_list[i_p+1].set_ylim((1.2*min_y,1.2*max_y))\n",
    "                ax_list[i_p+1].set_ylabel(to_plot[\"ylabel\"])\n",
    "\n",
    "\n",
    "            #make multiple frame for the beginning and the end of the animation\n",
    "            max_k=1\n",
    "            if i in [0, len(energy_list) - 1]:\n",
    "                max_k=10\n",
    "            #run over the duplicate frames\n",
    "            for k in range(max_k):\n",
    "                filename = f'{i}_{k}.png'\n",
    "                filenames.append(filename)\n",
    "\n",
    "                # save frame\n",
    "                plt.savefig(filename)\n",
    "            plt.close()\n",
    "            plt.show()\n",
    "\n",
    "    # build gif\n",
    "    gif_path = f'gif_out/{max(energy_list)}_{gif_name}.gif'\n",
    "    with imageio.get_writer(gif_path, mode='I') as writer:\n",
    "        for filename in filenames:\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    # Remove files\n",
    "    for filename in set(filenames):\n",
    "        os.remove(filename)\n",
    "\n",
    "    return gif_path\n",
    "\n",
    "def interpret_NEB_atom_list_H_P(energy_list, atom_list_list, conn, n_out):\n",
    "    # sourcery no-metrics skip: default-mutable-arg\n",
    "    \n",
    "    print(conn)\n",
    "    in_connection_length, out_connection_length  = [], [] #expected length for each connection\n",
    "    min_x, max_x, min_y, max_y = 1E10,-1E10,1E10,-1E10\n",
    "    out_energy_length, in_energy_length = [], [] #energy for each connection\n",
    "    out_pos, in_pos = [], []\n",
    "\n",
    "    for i in range(len(energy_list)):\n",
    "        \n",
    "        #check if we just receive inside connection from conn or conn_in and out \n",
    "        if len(conn)==2:\n",
    "            conn_in, conn_out = conn\n",
    "        else:  \n",
    "            conn_in, conn_out = conn, [ (i,(i+1)%n_out ) for i in range(n_out)]\n",
    "\n",
    "        out_connection_list, out_active_connection_length =[], []\n",
    "        for  c in conn_out:\n",
    "            x1,x2 = atom_list_list[i][0][c[0]], atom_list_list[i][0][c[1]]\n",
    "            y1,y2 = atom_list_list[i][1][c[0]], atom_list_list[i][1][c[1]]\n",
    "            xl,yl = [x1, x2] , [y1, y2]\n",
    "            min_x = min(min_x, x1, x2)\n",
    "            min_y = min(min_y, y1, y2)\n",
    "            max_x = max(max_x, x1, x2)\n",
    "            max_y = max(max_y, y1, y2)\n",
    "            out_connection_list.append( [xl, yl] )\n",
    "            if i == 0:\n",
    "                out_connection_length.append(math.sqrt((x1-x2)**2 + (y1-y2)**2))\n",
    "            out_active_connection_length.append(math.sqrt((x1-x2)**2 + (y1-y2)**2))\n",
    "\n",
    "        energy_edge_out = [(out_connection_length[k] - out_active_connection_length[k])**2 for k in range(len(conn_out))]\n",
    "        out_energy_length.append(energy_edge_out)\n",
    "        out_pos.append(out_connection_list)\n",
    "\n",
    "        in_active_connection_length, in_connection_list = [], []\n",
    "        for  c in conn_in:\n",
    "            x1,x2 = atom_list_list[i][0][c[0]], atom_list_list[i][0][c[1]]\n",
    "            y1,y2 = atom_list_list[i][1][c[0]], atom_list_list[i][1][c[1]]\n",
    "            xl,yl = [x1, x2] , [y1, y2]\n",
    "            min_x = min(min_x, x1, x2)\n",
    "            min_y = min(min_y, y1, y2)\n",
    "            max_x = max(max_x, x1, x2)\n",
    "            max_y = max(max_y, y1, y2)\n",
    "            in_connection_list.append( [xl,yl])\n",
    "            if i == 0:\n",
    "                in_connection_length.append(math.sqrt((x1-x2)**2 + (y1-y2)**2))\n",
    "            in_active_connection_length.append(math.sqrt((x1-x2)**2 + (y1-y2)**2))\n",
    "\n",
    "        energy_edge_in = [(in_connection_length[k] - in_active_connection_length[k])**2 for k in range(len(conn_in))]\n",
    "        in_energy_length.append(energy_edge_in)\n",
    "        in_pos.append(in_connection_list)\n",
    "\n",
    "    return  (in_energy_length, out_energy_length), (in_pos, out_pos), (conn_in,conn_out), (min_x, max_x, min_y, max_y)\n",
    "\n",
    "\n",
    "# paths list is given by [PRE, PATH_DUMP, PATH_SCR, PATH_NEB, PATH_FINAL]\n",
    "def create_gif_transition_H_P(n_out, db, key_list, paths, full_output = False):\n",
    "\n",
    "    path_list = []\n",
    "    for keys in key_list:\n",
    "\n",
    "        NEB_main.NB_NODE = 20\n",
    "        NEB_main.TIMESTEP = 0.001\n",
    "        NEB_main.SPRING_INTER_REPLICA = 10000\n",
    "\n",
    "        reaction_coordinate_list, energy_list, atom_list_list = NEB_main.get_NEB(\n",
    "            db, str(0),keys[0],keys[1], keys[2], \n",
    "            PRE=paths[0], PATH_DUMP=paths[1], PATH_SCR=paths[2], PATH_NEB=paths[3], PATH_FINAL=paths[4])\n",
    "        \n",
    "\n",
    "        conn = db.db_pairs[keys[0]][keys[1]]['sols'][keys[2]]['conn']\n",
    "        conn = [[x[0]-1, x[1]-1] for x in conn]\n",
    "        protein_pair = db.load_protein_pair(keys[0],keys[1], keys[2])\n",
    "        protein_pair.plot( axes = None, same_plot = True)\n",
    "\n",
    "        energy_tuple, pos_tuple, conn_tuple, box = interpret_NEB_atom_list_H_P(energy_list, atom_list_list, conn, n_out)\n",
    "        \n",
    "        #to_plot_test = {\"ys\":[energy_list, list(range(len(energy_list)))], \"labels\":[\"a.\",\"b\"], \"ylabel\":\"test\" }\n",
    "        gif_path = plot_gif(energy_list, conn_tuple, pos_tuple, energy_tuple, box, gif_name=f\"n_{str(keys)}\", list_of_plot=[], speed_up_zero = 1)\n",
    "        path_list.append(gif_path)\n",
    "\n",
    "    if full_output:\n",
    "        return path_list, (reaction_coordinate_list, energy_list, atom_list_list)\n",
    "\n",
    "    return path_list\n",
    "\n",
    "\n",
    "# paths list is given by [PRE, PATH_DUMP, PATH_SCR, PATH_NEB, PATH_FINAL]\n",
    "def create_gif_transition_HP_PP(n_out, db, key_list, paths, full_output = False):\n",
    "\n",
    "#\n",
    "#   IF IT DOESNT RUN, RUN THE SCRIPT IN TERMINAL TO GET THE CREDETIAL \n",
    "#\n",
    "    path_list = []\n",
    "    for keys in key_list:\n",
    "\n",
    "        NEB_binded_main.NB_NODE = 14\n",
    "        NEB_binded_main.TIMESTEP =  0.01\n",
    "        NEB_binded_main.SPRING_INTER_REPLICA = 10000\n",
    "\n",
    "        reaction_coordinate_list, energy_list, atom_list_list, protein_pair, edges = NEB_binded_main.get_NEB(\n",
    "            db, str(0),keys[0],keys[1], keys[2], \n",
    "            PRE=paths[0], PATH_DUMP=paths[1], PATH_SCR=paths[2], PATH_NEB=paths[3], PATH_FINAL=paths[4])\n",
    "\n",
    " \n",
    "\n",
    "        conn_in, conn_out = edges \n",
    "        \n",
    "        energy_tuple, pos_tuple, conn_tuple, box = interpret_NEB_atom_list_H_P(energy_list, atom_list_list, (conn_in, conn_out), n_out)\n",
    "\n",
    "        gif_path = plot_gif(energy_list, conn_tuple, pos_tuple, energy_tuple, box, gif_name=f\"binded_{str(keys)}\", speed_up_zero = 1)\n",
    "        path_list.append(gif_path)\n",
    "        \n",
    "    if full_output:\n",
    "        return path_list, (reaction_coordinate_list, energy_list, atom_list_list)\n",
    "\n",
    "    return path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting transition between two structure \n",
    "\n",
    "\n",
    "PRE = ''\n",
    "PATH_DUMP = 'temp/'\n",
    "PATH_SCR = 'lammps_util/script/'\n",
    "PATH_NEB = 'lammps_util/script/neb_task.lj'\n",
    "PATH_FINAL = 'lammps_util/script/prion_neb_pos.lj'\n",
    "\n",
    "keys = (1737806584325749351, -8771402139612191995, -4281357692739835561)\n",
    "\n",
    "\n",
    "output_path_list, (reaction_coordinate_list_binded, energy_list_binded, atom_list_list_binded) = create_gif_transition_HP_PP(5, db, [keys], [PRE, PATH_DUMP, PATH_SCR, PATH_NEB, PATH_FINAL], full_output = True)\n",
    "#output_path_list, vec_out = create_gif_transition_H_P(5, db, [keys], [PRE, PATH_DUMP, PATH_SCR, PATH_NEB, PATH_FINAL], full_output = True)\n",
    "\n",
    "\n",
    "trans_func_test = get_translation_binded_function_neb(db, keys[0], keys[1], keys[2])\n",
    "list_pos_bottom, list_pos_top = trans_func_test(atom_list_list_binded)\n",
    "\n",
    "for j in range(len(list_pos_bottom)):\n",
    "    plt.plot(*list_pos_bottom[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot transition rate, population simulation + structure (FIG.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_for_R(sol_dick,key, binded, temp_list, path, is_plot = False ):\n",
    "\n",
    "    if not isinstance(temp_list, list):\n",
    "        temp_list = [temp_list]\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    max_lenght = 0\n",
    "    for temp in temp_list:\n",
    "        n_sample = len(sol_dick[key][binded][temp])\n",
    "        for s in range(n_sample):\n",
    "            n_ik = len(sol_dick[key][binded][temp][s][0])\n",
    "            for ik in range(n_ik):\n",
    "                if ik%2==0 or binded==0:\n",
    "                    l = len([sol_dick[key][binded][temp][s][k][ik] for k in range(len(sol_dick[key][binded][temp][s]))])\n",
    "                    if l  > max_lenght:\n",
    "                        max_lenght = l \n",
    "\n",
    "    run_nb = 0\n",
    "    for temp in temp_list:\n",
    "        n_sample = len(sol_dick[key][binded][temp])\n",
    "        for s in range(n_sample):\n",
    "            n_ik = len(sol_dick[key][binded][temp][s][0])\n",
    "            for ik in range(n_ik):\n",
    "                if ik%2==0 or binded==0:\n",
    "                    data_temp = [sol_dick[key][binded][temp][s][k][ik] for k in range(len(sol_dick[key][binded][temp][s]))]\n",
    "                    if len(data_temp)==max_lenght:\n",
    "                        data[f'run_nb{run_nb}'] = data_temp\n",
    "                        run_nb+=1\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    if is_plot:\n",
    "        df.plot(subplots=False, figsize=(16,16))\n",
    "        plt.plot()\n",
    "    \n",
    "    with open(path, 'wb') as f:\n",
    "        feather.write_feather(df, f)\n",
    "\n",
    "    return max_lenght\n",
    "\n",
    "def compute_markov(sol_dick, key, binded ,path, merge_close=0.95):\n",
    "\n",
    "    x_t = []\n",
    "    p_t = []\n",
    "    r_12 = []\n",
    "    dr_12 = []\n",
    "    r_21 = []\n",
    "    dr_21 = []\n",
    "    dp_t = []\n",
    "\n",
    "    ratio = [merge_close,1/merge_close] \n",
    "    distinct_temp_dict = {}\n",
    "    \n",
    "    for key_temp in sol_dick[key][binded].keys():\n",
    "        closest_temp = -100000\n",
    "        for distinct_key in distinct_temp_dict.keys():\n",
    "            if float(distinct_key)/float(key_temp) > ratio[0] and float(distinct_key)/float(key_temp) < ratio[1]:\n",
    "                closest_temp = distinct_key\n",
    "        \n",
    "        if closest_temp!=  -100000:\n",
    "            distinct_temp_dict[closest_temp].append(key_temp)\n",
    "        else:\n",
    "            distinct_temp_dict[key_temp] = [key_temp]\n",
    "\n",
    "\n",
    "\n",
    "    for distinct_temp in distinct_temp_dict.keys():\n",
    "        #sol_dick[key][binded].keys():\n",
    "\n",
    "\n",
    "    \n",
    "        max_length = save_for_R(sol_dick,key, binded, distinct_temp_dict[distinct_temp], path, is_plot=False )\n",
    "        process = subprocess.Popen (f\"Rscript --vanilla markov.R  /Users/mathieuouellet/Desktop/AMP/AMP/src/polygon/test.feather\", shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out, err = process.communicate()\n",
    "\n",
    "        out_val = [ float(x) for x in str(out).split('\\\"')[1].split(\",\")]\n",
    "        a,b = out_val[1], out_val[2]\n",
    "        da,db = out_val[5], out_val[6]\n",
    "        r_12.append(a)\n",
    "        dr_12.append(da)\n",
    "        r_21.append(b)\n",
    "        dr_21.append(db)\n",
    "        \n",
    "\n",
    "        #get error if no transition prion->healthy found bu healthy->prion found \n",
    "        if r_21[-1]==0 and r_12[-1]!=0:\n",
    "            nb_step_prion = 0\n",
    "\n",
    "            for temp in distinct_temp_dict[distinct_temp]:\n",
    "                n_sample = len(sol_dick[key][binded][temp])\n",
    "                for s in range(n_sample):\n",
    "                    n_ik = len(sol_dick[key][binded][temp][s][0])\n",
    "                    for ik in range(n_ik):\n",
    "                        run = [sol_dick[key][binded][temp][s][k][ik] for k in range(len(sol_dick[key][binded][temp][s]))]\n",
    "                        if len(run) == max_length:\n",
    "                            nb_step_prion+= len([v for v in run if v==1])\n",
    "\n",
    "            dr_21[-1] =  1/nb_step_prion if nb_step_prion>0 else 1\n",
    "            db = dr_21[-1]\n",
    "            \n",
    "        dp =  math.sqrt((b**2 * da**2 + a**2 * db**2)/((a + b+1E-10)**4) )\n",
    "        x_t.append(distinct_temp)\n",
    "        p_t.append(a/(a+b+1E-10))\n",
    "        dp_t.append(dp)\n",
    "\n",
    "\n",
    "    return (x_t, p_t, dp_t), (r_12,r_21, dr_12, dr_21)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def load_pickle_full_sim_from_dump(path_folder, dump_done, dump_dick, database, nb_int, nb_out):\n",
    "\n",
    "    onlyfiles = [f for f in listdir(path_folder) if isfile(join(path_folder, f))]\n",
    "\n",
    "    print(len(onlyfiles))\n",
    "    NJob = 12\n",
    "\n",
    "    file_todo_list = [file_name for file_name in onlyfiles if file_name not in dump_done and file_name!=\".DS_Store\"]\n",
    "    job_list = []\n",
    "\n",
    "\n",
    "    print(\"number of job todo: \" + str(len(file_todo_list)))\n",
    "\n",
    "    current_job = []\n",
    "    for file_name in file_todo_list:\n",
    "        splitted = file_name.split('_')\n",
    "        keys = ( int(splitted[2]), int(splitted[3]),int(splitted[4]) )\n",
    "        isbinded = eval(splitted[5])\n",
    "        temp = float(splitted[6]) \n",
    "        key_h, key_p, key_s = keys\n",
    "\n",
    "        if (key_h, key_p, key_s) not in dump_dick:\n",
    "            (func_translate, func_translate_binded), (endpoint_pca, endpoint_pca_bind) = get_reaction_coordinate_function(database, keys, nb_int, nb_out)\n",
    "            dump_dick[(key_h, key_p, key_s)] = [{},{},((func_translate, func_translate_binded), (endpoint_pca, endpoint_pca_bind))]\n",
    "            print(\"translation func added\")\n",
    "\n",
    "        data_for_task = (path_folder+file_name, dump_dick[(key_h, key_p, key_s)][2], (temp, isbinded, file_name, keys))\n",
    "        if len(current_job)<NJob:\n",
    "            current_job.append(data_for_task)\n",
    "        else:\n",
    "            job_list.append(current_job)\n",
    "            current_job = []\n",
    "            \n",
    "    if len(current_job)>0:\n",
    "        job_list.append(current_job)\n",
    "\n",
    "    pool = Pool(processes=6)\n",
    "\n",
    "\n",
    "    for job in job_list:\n",
    "        dill.settings['recurse'] = True\n",
    "        \n",
    "        # call the function for each item in parallel\n",
    "        payload = [ dill.dumps(j) for j in job ] \n",
    "        \n",
    "        try:\n",
    "            result = pool.map(dumpWorker.run_dill_encoded, payload)\n",
    "\n",
    "            for i in range(len(result)):\n",
    "                temp = job[i][2][0]\n",
    "                isbinded = job[i][2][1]\n",
    "                conf_list = np.transpose(np.array(result[i]))\n",
    "                filename = job[i][2][2]\n",
    "                keys = job[i][2][3]\n",
    "                dump_done.append(filename)\n",
    "                print(filename)\n",
    "\n",
    "\n",
    "                if isbinded:\n",
    "                    if temp not in dump_dick[keys][1]:\n",
    "                        dump_dick[keys][1][temp] = [conf_list]\n",
    "                    else:\n",
    "                        dump_dick[keys][1][temp].append(conf_list)\n",
    "                else:\n",
    "                    if temp not in  dump_dick[keys][0]:\n",
    "                        dump_dick[keys][0][temp] = [conf_list]\n",
    "                    else:\n",
    "                        dump_dick[keys][0][temp].append(conf_list)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pool.close()\n",
    "        #list(my_map(pool, dumpWorker.get_conformation_from_DUMP, job))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def load_pickle_full_sim(path_folder, file_done, sol_dick):\n",
    "\n",
    "    onlyfiles = [f for f in listdir(path_folder) if isfile(join(path_folder, f))]\n",
    "\n",
    "    print(len(onlyfiles))\n",
    "    for file_name in onlyfiles:\n",
    "        if file_name not in file_done:\n",
    "\n",
    "            spl_key = re.split('\\(|\\)',file_name)[1]\n",
    "            key_h, key_p, key_s = [int(v) for v in re.split(',',spl_key)]\n",
    "            print(key_h, key_p, key_s, sep=',')\n",
    "            \n",
    "            if (key_h, key_p, key_s) not in sol_dick:\n",
    "                sol_dick[(key_h, key_p, key_s)] = [{},{}]\n",
    "\n",
    "            file_done.append(file_name)\n",
    "            print(path_folder, file_name)\n",
    "            saved = Save_file_full_sim.load(path_folder + file_name)\n",
    "\n",
    "\n",
    "            nonbinded_dict, binded_dict =  get_conformation_from_saved(\"None\", saved=saved, binded_dict=None, nonbinded_dict=None)\n",
    "            \n",
    "            data_non_binded_dict = sol_dick[(key_h, key_p, key_s)][0]\n",
    "            data_binded_dict = sol_dick[(key_h, key_p, key_s)][1]\n",
    "            \n",
    "            merge_dict(data_non_binded_dict, nonbinded_dict)\n",
    "            merge_dict(data_binded_dict, binded_dict)\n",
    "            sol_dick[(key_h, key_p, key_s)] = (data_non_binded_dict, data_binded_dict)\n",
    "\n",
    "\n",
    "def plot_corr_prion(datab, sol_dick, plot_list=[], threshold = 0.4, is_plot = False, func_from_key = None):\n",
    "\n",
    "    list_temp = []\n",
    "    list_bind_delta = []\n",
    "    list_non_bind_delta = []\n",
    "    ratio_bind_energy = []\n",
    "    ratio_bind_temperature = []\n",
    "    plotted_nb = 0\n",
    "    non_plotted_nb = 0\n",
    "\n",
    "    list_key_plot = []\n",
    "    list_full_data = []\n",
    "\n",
    "    for key in plot_list :\n",
    "\n",
    "        plotted_nb+=1\n",
    "        list_key_plot.append(key)\n",
    "\n",
    "        path = \"/Users/mathieuouellet/Desktop/AMP/AMP/src/polygon/test.feather\"\n",
    "        (x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21) = compute_markov(sol_dick, key, 0, path)\n",
    "        (x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b) = compute_markov(sol_dick, key, 1, path)\n",
    "\n",
    "        x_t, p_t, dp_t, r_12, r_21, dr_12, dr_21 = (list(t) for t in zip(*sorted(zip(x_t, p_t, dp_t, r_12, r_21, dr_12, dr_21))))\n",
    "        x_t_b, p_t_b, dp_t_b, r_12_b, r_21_b, dr_12_b, dr_21_b = (list(t) for t in zip(*sorted(zip(x_t_b, p_t_b, dp_t_b, r_12_b, r_21_b, dr_12_b, dr_21_b))))\n",
    "\n",
    "\n",
    "        list_full_data.append([(x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21),(x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b)])\n",
    "\n",
    "        index_binded = next((i for i, x in enumerate(p_t_b) if x>threshold ), -1)\n",
    "        index_non_binded = next((i for i, x in enumerate(p_t) if x>threshold ), -1)\n",
    "\n",
    "        firt_t_binded = x_t_b[index_binded]\n",
    "        firt_t_non_binded = x_t[index_non_binded]\n",
    "\n",
    "        delta_binded = (x_t_b[index_binded+1] -  x_t_b[index_binded-1])/4\n",
    "        delta_non_binded = (x_t[index_non_binded+1] -  x_t[index_non_binded-1])/4\n",
    "\n",
    "        #print(*key,firt_t_non_binded,firt_t_binded, sep=',')\n",
    "        list_temp.append((firt_t_non_binded,firt_t_binded,delta_non_binded,delta_binded ))\n",
    "\n",
    "        binded_energy = datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['NEB_HP_PP_energy']\n",
    "        free_energy = datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['NEB_HP_energy']\n",
    "        delta_binded = max(binded_energy)-binded_energy[0]\n",
    "        delta_free = max(free_energy)-free_energy[0]\n",
    "        list_bind_delta.append(delta_binded)\n",
    "        list_non_bind_delta.append(delta_free)\n",
    "        ratio_bind_energy.append(delta_binded/delta_free)\n",
    "        ratio_bind_temperature.append(firt_t_binded/firt_t_non_binded)\n",
    "        print(key)\n",
    "        print(datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['conn'])\n",
    "        print(func_from_key(key), list_temp[-1][1], list_temp[-1][0], list_temp[-1][1]-list_temp[-1][0] )\n",
    "\n",
    "        if is_plot:\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            #(x_t, p_t, dp_t)x_t_b, p_t_b, dp_t_b)\n",
    "            ax[0,0].set_xscale('log')\n",
    "            ax[0,0].errorbar(x_t_b, [1-p for p in p_t_b],   yerr=dp_t_b, fmt='X', c='g', label = \"healthy (bind)\")\n",
    "            ax[0,0].errorbar(x_t_b, p_t_b,                   yerr=dp_t_b, fmt='X', c='r', label = \"prion (bind)\")\n",
    "            #ax[0,0].plot(t_list, o_list_bind, 'o', c='y', label=\"other (bind)\")\n",
    "            ax[0,0].legend()\n",
    "\n",
    "            ax[0,1].errorbar(x_t, [1-p for p in p_t], yerr=dp_t, fmt='x', c='g', label = \"healthy (free)\")\n",
    "            ax[0,1].errorbar(x_t, p_t,                yerr=dp_t, fmt='x', c='r', label = \"prion (free)\")\n",
    "            #ax[0,1].plot(t_list_bind, o_list, 'x', c='y', label=\"other (free)\")\n",
    "            ax[0,1].legend()\n",
    "            ax[0,1].set_xscale('log')\n",
    "\n",
    "            ax[1,0].set_xscale(\"log\")\n",
    "            ax[1,0].set_yscale('log')\n",
    "            #cap for the plot for the infinite uncertainty one\n",
    "            dr_12 = [ (dval if dval<1000*val else 0) for val,dval in zip(r_12, dr_12) ]\n",
    "            dr_21 = [ (dval if dval<1000*val else 0) for val,dval in zip(r_21, dr_21) ]\n",
    "            dr_12_b = [ (dval if dval<1000*val else 0) for val,dval in zip(r_12_b, dr_12_b) ]\n",
    "            dr_21_b = [ (dval if dval<1000*val else 0) for val,dval in zip(r_21_b, dr_21_b) ]\n",
    "\n",
    "            ax[1,0].errorbar(x_t, r_12,  yerr=dr_12,        fmt='x', c='r', label=\"r_12\")\n",
    "            ax[1,0].errorbar(x_t, r_21,  yerr=dr_21,        fmt='x', c='g', label=\"r_21\")\n",
    "            ax[1,0].errorbar(x_t_b, r_12_b,  yerr=dr_12_b,    fmt='X', c='r', label=\"r_12_b\")\n",
    "            ax[1,0].errorbar(x_t_b, r_21_b,  yerr=dr_21_b,    fmt='X', c='g', label=\"r_21_b\")\n",
    "            ax[1,0].legend()\n",
    "\n",
    "            plot_binded(datab, key, ax[1,1])\n",
    "            plt.savefig(f'./figure/test/rates_{key[0]}_{key[1]}_{key[2]}_papuche.pdf')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    return list_temp, list_key_plot, list_full_data\n",
    "\n",
    "def plot_corr_prion(datab, sol_dick, plot_list=[], threshold = 0.4, is_plot = False, func_from_key = None):\n",
    "\n",
    "    list_temp = []\n",
    "    list_bind_delta = []\n",
    "    list_non_bind_delta = []\n",
    "    ratio_bind_energy = []\n",
    "    ratio_bind_temperature = []\n",
    "    plotted_nb = 0\n",
    "    non_plotted_nb = 0\n",
    "\n",
    "    list_key_plot = []\n",
    "    list_full_data = []\n",
    "\n",
    "    for key in plot_list :\n",
    "\n",
    "        plotted_nb+=1\n",
    "        list_key_plot.append(key)\n",
    "\n",
    "        path = \"/Users/mathieuouellet/Desktop/AMP/AMP/src/polygon/test.feather\"\n",
    "        (x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21) = compute_markov(sol_dick, key, 0, path)\n",
    "        (x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b) = compute_markov(sol_dick, key, 1, path)\n",
    "\n",
    "        x_t, p_t, dp_t, r_12, r_21, dr_12, dr_21 = (list(t) for t in zip(*sorted(zip(x_t, p_t, dp_t, r_12, r_21, dr_12, dr_21))))\n",
    "        x_t_b, p_t_b, dp_t_b, r_12_b, r_21_b, dr_12_b, dr_21_b = (list(t) for t in zip(*sorted(zip(x_t_b, p_t_b, dp_t_b, r_12_b, r_21_b, dr_12_b, dr_21_b))))\n",
    "\n",
    "\n",
    "        list_full_data.append([(x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21),(x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b)])\n",
    "\n",
    "        index_binded = next((i for i, x in enumerate(p_t_b) if x>threshold ), -1)\n",
    "        index_non_binded = next((i for i, x in enumerate(p_t) if x>threshold ), -1)\n",
    "\n",
    "        firt_t_binded = x_t_b[index_binded]\n",
    "        firt_t_non_binded = x_t[index_non_binded]\n",
    "\n",
    "        delta_binded = (x_t_b[index_binded+1] -  x_t_b[index_binded-1])/4\n",
    "        delta_non_binded = (x_t[index_non_binded+1] -  x_t[index_non_binded-1])/4\n",
    "\n",
    "        #print(*key,firt_t_non_binded,firt_t_binded, sep=',')\n",
    "        list_temp.append((firt_t_non_binded,firt_t_binded,delta_non_binded,delta_binded ))\n",
    "\n",
    "        binded_energy = datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['NEB_HP_PP_energy']\n",
    "        free_energy = datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['NEB_HP_energy']\n",
    "        delta_binded = max(binded_energy)-binded_energy[0]\n",
    "        delta_free = max(free_energy)-free_energy[0]\n",
    "        list_bind_delta.append(delta_binded)\n",
    "        list_non_bind_delta.append(delta_free)\n",
    "        ratio_bind_energy.append(delta_binded/delta_free)\n",
    "        ratio_bind_temperature.append(firt_t_binded/firt_t_non_binded)\n",
    "        print(key)\n",
    "        print(datab.db_pairs[key[0]][key[1]]['sols'][key[2]]['conn'])\n",
    "        print(func_from_key(key), list_temp[-1][1], list_temp[-1][0], list_temp[-1][1]-list_temp[-1][0] )\n",
    "\n",
    "        if is_plot:\n",
    "\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            #(x_t, p_t, dp_t)x_t_b, p_t_b, dp_t_b)\n",
    "            ax[0,0].set_xscale('log')\n",
    "            ax[0,0].errorbar(x_t_b, [1-p for p in p_t_b],   yerr=dp_t_b, fmt='X', c='g', label = \"healthy (bind)\")\n",
    "            ax[0,0].errorbar(x_t_b, p_t_b,                   yerr=dp_t_b, fmt='X', c='r', label = \"prion (bind)\")\n",
    "            #ax[0,0].plot(t_list, o_list_bind, 'o', c='y', label=\"other (bind)\")\n",
    "            ax[0,0].legend()\n",
    "\n",
    "            ax[0,1].errorbar(x_t, [1-p for p in p_t], yerr=dp_t, fmt='x', c='g', label = \"healthy (free)\")\n",
    "            ax[0,1].errorbar(x_t, p_t,                yerr=dp_t, fmt='x', c='r', label = \"prion (free)\")\n",
    "            #ax[0,1].plot(t_list_bind, o_list, 'x', c='y', label=\"other (free)\")\n",
    "            ax[0,1].legend()\n",
    "            ax[0,1].set_xscale('log')\n",
    "\n",
    "            ax[1,0].set_xscale(\"log\")\n",
    "            ax[1,0].set_yscale('log')\n",
    "            #cap for the plot for the infinite uncertainty one\n",
    "            dr_12 = [ (dval if dval<1000*val else 0) for val,dval in zip(r_12, dr_12) ]\n",
    "            dr_21 = [ (dval if dval<1000*val else 0) for val,dval in zip(r_21, dr_21) ]\n",
    "            dr_12_b = [ (dval if dval<1000*val else 0) for val,dval in zip(r_12_b, dr_12_b) ]\n",
    "            dr_21_b = [ (dval if dval<1000*val else 0) for val,dval in zip(r_21_b, dr_21_b) ]\n",
    "\n",
    "            ax[1,0].errorbar(x_t, r_12,  yerr=dr_12,        fmt='x', c='r', label=\"r_12\")\n",
    "            ax[1,0].errorbar(x_t, r_21,  yerr=dr_21,        fmt='x', c='g', label=\"r_21\")\n",
    "            ax[1,0].errorbar(x_t_b, r_12_b,  yerr=dr_12_b,    fmt='X', c='r', label=\"r_12_b\")\n",
    "            ax[1,0].errorbar(x_t_b, r_21_b,  yerr=dr_21_b,    fmt='X', c='g', label=\"r_21_b\")\n",
    "            ax[1,0].legend()\n",
    "\n",
    "            plot_binded(datab, key, ax[1,1])\n",
    "            plt.savefig(f'./figure/test/rates_{key[0]}_{key[1]}_{key[2]}.pdf')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    return list_temp, list_key_plot, list_full_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/mathieuouellet/Desktop/n=5_5deg_2_fig4b\"\n",
    "db_fig_4b = database.Database(path)\n",
    "db_fig_4b.clear_all_lock()\n",
    "\n",
    "with open('conf_of_dump_of_full_sim_2.dill', 'rb') as in_strm:\n",
    "        dump_done_2, dump_dict_2 = dill.load(in_strm)\n",
    "list_temp_2, list_key_plot_2, list_full_data_2 = plot_corr_prion(db_fig_4b, dump_dict_2, plot_list=[keys], threshold = 0.05, is_plot = True, func_from_key = lambda key: 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.odr import *\n",
    "\n",
    "\n",
    "def funcArr(p, x):\n",
    "            a,b,c, = p\n",
    "            return a*np.exp( np.divide(- b, x-c) )\n",
    "\n",
    "\n",
    "def get_beta(r12,r21,dr21,dr12, func, init):\n",
    "\n",
    "\n",
    "\n",
    "    data_c = [[x[0],x[1],x[2],x[3]] for x in zip(r12,r21,dr21,dr12) if x[0]>0 or x[1]>0]\n",
    "\n",
    "\n",
    "    r_12_c , r_21_c, dr_21_c, dr_12_c = list(zip(*data_c))\n",
    "    # Create a model for fitting.\n",
    "    quad_model = Model(func)\n",
    "    # Create a RealData object using our initiated data from above.\n",
    "    data_free = RealData( np.array(r_12_c),np.array(r_21_c), sy=np.array(dr_21_c), sx=(np.array(dr_12_c)))\n",
    "    # Set up ODR with the model and data.\n",
    "    odr = ODR(data_free, quad_model, beta0=init)\n",
    "    # Run the regression.\n",
    "    out = odr.run()\n",
    "\n",
    "\n",
    "    return out.beta\n",
    "\n",
    "def get_beta_nox(xt,r,dr, func, init, overwrite=False):\n",
    "\n",
    "\n",
    "\n",
    "    data_c = [[x[0],x[1],x[2]] for x in zip(xt,r,dr) if x[0]>0 or x[1]>0]\n",
    "\n",
    "\n",
    "    xt_c , r_c, dr_c = list(zip(*data_c))\n",
    "    # Create a model for fitting.\n",
    "    quad_model = Model(func)\n",
    "    # Create a RealData object using our initiated data from above.\n",
    "    data_free = RealData( np.array(xt_c),np.array(r_c), sy=np.array(dr_c))\n",
    "    # Set up ODR with the model and data.\n",
    "    odr = ODR(data_free, quad_model, beta0=init)\n",
    "    # Run the regression.\n",
    "    out = odr.run()\n",
    "\n",
    "\n",
    "    return out.beta, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_beta12 = []\n",
    "list_beta12_b = []\n",
    "list_beta21 = []\n",
    "list_beta21_b = []\n",
    "\n",
    "def plot_():\n",
    "\n",
    "    for i in range(len(list_full_data_2)):\n",
    "        (x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21),(x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b) = list_full_data_2[i]\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(10,10))\n",
    "\n",
    "\n",
    "        def removeZero(x,r,dr):\n",
    "            return list(zip( *[(v[0],v[1],v[2]) for v in zip(x,r,dr ) if v[1]!=0]))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        for axi in range(2):\n",
    "\n",
    "            v = removeZero(x_t,r_12,dr_12)\n",
    "            axs[0,axi].errorbar(np.divide(1,np.array(v[0])),v[1], marker='o', yerr=v[2], ls='none', label=\"free 12\", c='b')\n",
    "            v = removeZero(x_t_b,r_12_b,dr_12_b)\n",
    "            axs[0,axi].errorbar(np.divide(1,np.array(v[0])),v[1], marker='o', label=\"bound 12\",  yerr= v[2],  ls='none', c='y')\n",
    "            v = removeZero(x_t,r_21,dr_21)\n",
    "            axs[0,axi].errorbar(np.divide(1,np.array(v[0])),v[1],marker='o', yerr= v[2], ls='none', label=\"free 21\", c='c')\n",
    "            v = removeZero(x_t_b,r_21_b,dr_21_b)\n",
    "            axs[0,axi].errorbar(np.divide(1,np.array(v[0])),v[1], marker='o', label=\"bound 21\",  yerr= v[2],  ls='none', c='r')\n",
    "\n",
    "\n",
    "        def clearHigherThan(x,r,dr, maxT, minT,index=0):\n",
    "            return list(zip( *[(v[0],v[1],v[2]) for v in zip(x,r,dr ) if v[index]< maxT and v[index]> minT]))\n",
    "\n",
    "        def clearZero(lst):\n",
    "            return [1 for l in lst]\n",
    "\n",
    "\n",
    "        dr_12 = clearZero(dr_12)\n",
    "        dr_12_b = clearZero(dr_12_b)\n",
    "        dr_21 = clearZero(dr_21)\n",
    "        dr_21_b = clearZero(dr_21_b)\n",
    "\n",
    "        min_T =  1/(10E4)\n",
    "        max_T =1/(6E3)\n",
    "        x_t_12,r_12,dr_12 = clearHigherThan(x_t,r_12,dr_12,max_T,min_T)\n",
    "        x_t_21,r_21,dr_21 = clearHigherThan(x_t,r_21,dr_21,max_T,min_T)\n",
    "\n",
    "        min_T =  1/(2E4)\n",
    "        max_T =1/(4E3)\n",
    "        x_t_b_21,r_21_b,dr_21_b = clearHigherThan(x_t_b,r_21_b,dr_21_b,max_T,min_T)\n",
    "\n",
    "        min_T =  1/(2E4)\n",
    "        max_T =1/(4E3)\n",
    "        x_t_b_12,r_12_b,dr_12_b = clearHigherThan(x_t_b,r_12_b,dr_12_b,max_T,min_T)\n",
    "\n",
    "\n",
    "        overwrite = False\n",
    "\n",
    "        #plt.plot( [1E-6,1E-2],[1E-6,1E-2])\n",
    "        func = funcArr\n",
    "        init =  [ 3.16641779e-02,  4.93747260e-04, -7.42202232e-06]\n",
    "\n",
    "        #[ 3E-1,   1E-5, 0]# ,-1.47747508]\n",
    "\n",
    "\n",
    "        beta12, func12 = get_beta_nox(x_t_12,r_12,dr_12,func,init, overwrite )\n",
    "        beta12_b, func12_b = get_beta_nox(x_t_b_12,r_12_b,dr_12_b,func,init, overwrite)\n",
    "        beta21, func21 = get_beta_nox(x_t_21,r_21,dr_21,func,init,overwrite )\n",
    "        beta21_b, func21_b = get_beta_nox(x_t_b_21,r_21_b,dr_21_b,func,init,overwrite)\n",
    "\n",
    "\n",
    "        x_fit = np.linspace( math.log(1E-6), math.log(5E-3), 100)\n",
    "        x_fit = np.exp(x_fit)\n",
    "        inv_x_fit = np.divide(1,x_fit)\n",
    "\n",
    "        y_fit_12 = func12(beta12, x_fit)\n",
    "        y_fit_b_12 = func12_b(beta12_b, x_fit)\n",
    "        y_fit_b_21 = func21_b(beta21_b, x_fit)\n",
    "        y_fit_21 = func21(beta21, x_fit)\n",
    "\n",
    "        for axi in range(2):\n",
    "            if axi==0:\n",
    "                linestyle='solid'\n",
    "            else:\n",
    "                linestyle='dashed'\n",
    "            axs[0,axi].plot(inv_x_fit, y_fit_12, label =\"free fit\", c='b', linestyle=linestyle)\n",
    "            axs[0,axi].plot(inv_x_fit, y_fit_b_12, label =\"bound fit\", c='y', linestyle=linestyle)\n",
    "            axs[0,axi].plot(inv_x_fit, y_fit_21, label =\"free fit\", c='c', linestyle=linestyle)\n",
    "            axs[0,axi].plot(inv_x_fit, y_fit_b_21, label =\"bound fit\", c='r', linestyle=linestyle)\n",
    "\n",
    "        list_beta12.append([func12,beta12])\n",
    "        list_beta12_b.append([func12_b, beta12_b])\n",
    "        list_beta21.append([func21, beta21])\n",
    "        list_beta21_b.append([func21_b, beta21_b])\n",
    "\n",
    "\n",
    "        for axi in range(2):\n",
    "            axs[0,axi].set_xlabel(\"rate P -> H\")\n",
    "            axs[0,axi].set_ylabel(\"rate H -> P\")\n",
    "            axs[0,axi].set_xscale('log')\n",
    "            axs[0,axi].set_yscale('log')\n",
    "            #ax.legend()\n",
    "\n",
    "        axs[0,1].set_ylim(1E-3,1E-1)\n",
    "        axs[0,1].set_xlim(1E2,7E3)\n",
    "\n",
    "        axs[0,0].set_xlim(4E3,4E4)\n",
    "        axs[0,0].set_ylim(1E-9,2E-2)\n",
    "\n",
    "        \n",
    "\n",
    "        #############################\n",
    "        #      SET THE CURVE        #\n",
    "        #############################\n",
    "\n",
    "        list_prionicity = []\n",
    "\n",
    "        tspace = np.exp(np.linspace(math.log(1E-6), math.log(1E-4),100))\n",
    "\n",
    "        p = np.divide( np.clip(func12(beta12,tspace),0,1), np.clip(func12(beta12,tspace),0,1)+np.clip(func21(beta21,tspace),0,1)+1E-10)\n",
    "        p_b = np.divide( np.clip(func12_b(beta12_b,tspace),0,1), np.clip(func12_b(beta12_b,tspace),0,1)+np.clip(func21_b(beta21_b,tspace),0,1)+1E-10)\n",
    "        \n",
    "        tp50= np.min(np.where(p>0.1,tspace,100000))\n",
    "        tp50_b= np.min(np.where(p_b>0.1,tspace,100000))\n",
    "\n",
    "        list_prionicity.append([(tp50-tp50_b)/(tp50_b+tp50),tp50,tp50_b])\n",
    "\n",
    "        #axs[1,0].set_xlim((5E-6,30E-4))\n",
    "        axs[1,0].plot(np.divide(1,tspace),p)\n",
    "        axs[1,0].plot(np.divide(1,tspace),p_b)\n",
    "        axs[1,0].set_xscale(\"log\")\n",
    "        axs[1,0].set_ylim(0,1.1)\n",
    "        axs[1,0].set_xlim(2E2,2E5)\n",
    "\n",
    "        #x_t, p_t, dp_t\n",
    "        (x_t, p_t, dp_t), (r_12,r_21,dr_12,dr_21),(x_t_b, p_t_b, dp_t_b), (r_12_b,r_21_b,dr_12_b,dr_21_b) = list_full_data_2[i]\n",
    "\n",
    "        x_t_c, p_t_c, dp_t_c= clearHigherThan(x_t, p_t, dp_t,1,1E-4, index=1)\n",
    "        x_t_b_c, p_t_b_c, dp_t_b_c= clearHigherThan(x_t_b, p_t_b, dp_t_b,1,1E-4, index=1)\n",
    "\n",
    "        #axs[1,0].plot(x_t, p_t)\n",
    "        axs[1,0].errorbar(np.divide(1,x_t_c),p_t_c, marker='o', yerr= dp_t_c,  c='b', ls='none')\n",
    "        axs[1,0].errorbar(np.divide(1,x_t_b_c), p_t_b_c, marker='o', yerr= dp_t_b_c,  c='r', ls='none')\n",
    "\n",
    "\n",
    "        #############################\n",
    "        #      SET THE CURVE        #\n",
    "        #############################\n",
    "\n",
    "\n",
    "        binded_rate = [ (abs(1/(r[0]-r[1])) if (r[0]-r[1])!=0 else -1) for r in  zip(r_21_b, r_12_b)]\n",
    "        binded_rate_d = [(math.sqrt(r[0]**2 + r[1]**2)/((r[0]+r[1])**2) if (r[0]+r[1])>0 else -1) for r in  zip(dr_21_b, dr_12_b)]\n",
    "\n",
    "        rate = [ (abs(1/(r[0]-r[1])) if (r[0]-r[1])!=0 else -1) for r in  zip(r_21, r_12)]\n",
    "        rate_d = [(math.sqrt(r[0]**2 + r[1]**2)/((r[0]+r[1])**2)  if (r[0]+r[1])>0 else -1) for r in  zip(dr_21, dr_12)]\n",
    "\n",
    "        def find_nearest(array, value):\n",
    "            array = np.asarray(array)\n",
    "            idx = (np.abs(array - value)).argmin()\n",
    "            return idx\n",
    "\n",
    "\n",
    "\n",
    "        index_nearest = [find_nearest(np.array(x_t_b),v) for v in x_t]\n",
    "        ratio = [ (rate[i]/binded_rate[index_nearest[i]] if rate[i]!=0 else -1) for i in range(len(x_t)) ]\n",
    "\n",
    "        \n",
    "\n",
    "        axs[1,1].plot(np.divide(1,np.array(x_t)), ratio, 'o')\n",
    "        axs[1,1].errorbar(np.divide(1,np.array(x_t_b)),binded_rate, marker='o', yerr= binded_rate_d,  c='r', ls='none')\n",
    "        axs[1,1].errorbar(np.divide(1,np.array(x_t)),rate, marker='o', yerr= rate_d,  c='b', ls='none')\n",
    "        axs[1,1].set_yscale(\"log\")\n",
    "        axs[1,1].set_xscale(\"log\")\n",
    "\n",
    "        axs[0,0].legend()\n",
    "        axs[0,1].legend()\n",
    "\n",
    "        plt.savefig(f'./figure/main_prion.pdf')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifold plot (suppl 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_min_energy_matrix(pca_data, energy, boundary, n_box ,min_E, max_E):\n",
    "\n",
    "    x_list = np.linspace(boundary[0][0],boundary[0][1] ,n_box)\n",
    "    y_list = np.linspace(boundary[1][0],boundary[1][1] ,n_box)\n",
    "\n",
    "    min_E_log = math.log(min_E)\n",
    "    max_E_log = math.log(max_E)\n",
    "\n",
    "    Emin = np.full((n_box,n_box),max_E_log)\n",
    "    count = np.zeros((n_box,n_box))\n",
    "\n",
    "    for i in range(len(pca_data)):\n",
    "        x,y = pca_data[i][0], pca_data[i][1]\n",
    "        dx = x_list[1]-x_list[0]\n",
    "        dy = y_list[1]-y_list[0]\n",
    "        if x>=boundary[0][0] and x<=boundary[0][1] and y>=boundary[1][0] and y<=boundary[1][1]:\n",
    "            indx = math.floor(abs((boundary[0][0]-x)/dx))\n",
    "            indy = math.floor(abs((boundary[1][0]-y)/dy))\n",
    "            #print(indx,indy)\n",
    "            if energy[i] < Emin[indy,indx]:\n",
    "                if energy[i] < min_E_log :\n",
    "                    Emin[indy,indx] = min_E_log\n",
    "                else:\n",
    "                    Emin[indy,indx] = energy[i]\n",
    "\n",
    "            count[indy,indx] = count[indy,indx] +  1\n",
    "        \n",
    "    return Emin, count, (dx,dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_plot_path = True\n",
    "\n",
    "index_pca_binded = [0,4,2,3,1]\n",
    "\n",
    "minx,maxx = -1.2,1.5\n",
    "miny,maxy =  -0.3,0.3\n",
    "min_E_exponent = -9\n",
    "n_box = 100\n",
    "max_E = 1.0\n",
    "\n",
    "min_E = math.exp(min_E_exponent)\n",
    "boundary = [[minx,maxx],[miny,maxy]]\n",
    "\n",
    "#get the data point in the form of list of x1,y1,x2,y2\n",
    "text_path = f\"./pca_folder/{keys[0]}_{keys[1]}_{keys[2]}_low_temp.txt\"\n",
    "X = np.loadtxt(text_path, delimiter=',')\n",
    "X_noerr = X[:,1:]\n",
    "X_noerr_x = X_noerr[:,0:5]\n",
    "X_noerr_y = X_noerr[:,7:12]\n",
    "X_noerr = np.concatenate((X_noerr_x, X_noerr_y), axis=1)\n",
    "energy  = np.log(X[:,0] + min_E)\n",
    "\n",
    "\n",
    "output_path_list, vec_out = create_gif_transition_H_P(5, db, [keys], [PRE, PATH_DUMP, PATH_SCR, PATH_NEB, PATH_FINAL], full_output = True)\n",
    "\n",
    "\n",
    "#get the pca\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_noerr)\n",
    "\n",
    "#fit the data and get the grid for the plot\n",
    "pca_data = pca.transform(X_noerr)\n",
    "Emin, count, (dx,dy) = get_min_energy_matrix(pca_data, energy, boundary, n_box ,min_E, max_E)\n",
    "\n",
    "#load binded data\n",
    "text_path_bind = f\"./pca_folder/{keys[0]}_{keys[1]}_{keys[2]}_binded_low_temp.txt\"\n",
    "Xbind = np.loadtxt(text_path_bind, delimiter=',')\n",
    "Xbind_noerr = Xbind[:,1:]\n",
    "Xbind_noerr_x = Xbind_noerr[:,0:5]\n",
    "Xbind_noerr_y = Xbind_noerr[:,7:12]\n",
    "Xbind_noerr = np.concatenate((Xbind_noerr_x, Xbind_noerr_y), axis=1)\n",
    "\n",
    "#fit the data for binded and get the grid for plot\n",
    "pca_data_bind = pca.transform(Xbind_noerr)\n",
    "energy_bind = np.log(Xbind[:,0] + min_E)\n",
    "Emin_bind, count_bind, (dx,dy) = get_min_energy_matrix(pca_data_bind, energy_bind, boundary, n_box ,min_E, max_E)\n",
    "\n",
    "#plot both energy heatmap\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.scatter([v[0] for v in pca_data], [v[1] for v in pca_data],c=energy,  alpha = 0.1)\n",
    "ax1.set_xlim(minx,maxx )\n",
    "ax1.set_ylim(miny,maxy)\n",
    "ax2.scatter([v[0] for v in pca_data_bind], [v[1] for v in pca_data_bind],c=energy_bind,  alpha = 0.1)\n",
    "ax2.set_xlim(minx,maxx )\n",
    "ax2.set_ylim(miny,maxy)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.set_cmap('viridis')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,7))\n",
    "ax1.imshow(Emin, vmin=-7.5, vmax=-4.5)\n",
    "im = ax2.imshow(Emin_bind, vmin=-7.5, vmax=-4.5)\n",
    "\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "\n",
    "if is_plot_path:\n",
    "\n",
    "    #set up path\n",
    "    pos_list = get_neb_pos_list(vec_out[2])\n",
    "    path_h_x = pos_list[:,0:5]\n",
    "    path_h_y = pos_list[:,7:12]\n",
    "    path_h = np.concatenate((path_h_x, path_h_y), axis=1)\n",
    "    dim2_out_path_h= pca.transform(path_h)\n",
    "\n",
    "    trans_func_test = get_translation_binded_function_neb(db, keys[0], keys[1], keys[2])\n",
    "    list_pos_bottom, list_pos_top = trans_func_test(atom_list_list_binded)\n",
    "\n",
    "    #set up path binded\n",
    "    pos_list_bind = get_neb_pos_list(list_pos_bottom, zero_on = 0, rotate_on = 1)\n",
    "    index_pca_binded=[0,1,2,3,4]\n",
    "    path_bind_x = np.take(pos_list_bind,index_pca_binded,1)\n",
    "    path_bind_y = np.take(pos_list_bind, [7+v for v in index_pca_binded],1)\n",
    "    path_bind = np.concatenate((path_bind_x, path_bind_y), axis=1)\n",
    "    dim2_out_path_bind= pca.transform(path_bind)\n",
    "\n",
    "    ax1.plot([ abs((minx-v[0])/dx) for v in dim2_out_path_h] ,[ abs((miny-v[1])/dy) for v in dim2_out_path_h] , c='r')\n",
    "    ax2.plot([ abs((minx-v[0])/dx) for v in dim2_out_path_bind] ,[ abs((miny-v[1])/dy) for v in dim2_out_path_bind] , c='r')\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(f'./figure/energymap{keys[0]}_{keys[1]}_{keys[2]}_{sum(pca.explained_variance_ratio_)}.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = []\n",
    "temp_todo = [] \n",
    "id_todo = [] \n",
    "temp_target = 0.000316227766016838\n",
    "\n",
    "for path, currentDirectory, files in os.walk(\"/Volumes/Lab_math/sim_prion_2/dump\"):\n",
    "    for file in files:\n",
    "        if file.startswith(\"dump__1737806584325749351_-8771402139612191995_-4281357692739835561_True_\"):\n",
    "            temp = file.split(\"_\")[6]\n",
    "            if abs(float(temp) - temp_target)/temp_target<0.05: \n",
    "                ind = file.split(\"_\")[7]\n",
    "                todo.append(path + \"/\" + file)\n",
    "                temp_todo.append(temp)\n",
    "                id_todo.append(ind)\n",
    "    \n",
    "all_signal = []\n",
    "all_signal_type = []\n",
    "\n",
    "nb_done = 0 \n",
    "for ppp, temp_ppp, ind in zip(todo,temp_todo, id_todo):\n",
    "\n",
    "\n",
    "    d = dump.dump(ppp)  \n",
    "\n",
    "\n",
    "    nsnaps = len(d.snaps)\n",
    "    natoms = d.snaps[0].natoms\n",
    "    data_array_x = np.zeros((nsnaps,natoms))\n",
    "    data_array_y = np.zeros((nsnaps,natoms))\n",
    "\n",
    "    columns = []\n",
    "    for name in ['x','y']:\n",
    "        columns.append(d.names[name])\n",
    "\n",
    "    id = d.names[\"id\"]\n",
    "\n",
    "\n",
    "    for i, snap in enumerate(d.snaps):\n",
    "        atoms = snap.atoms\n",
    "        for j in range(natoms):\n",
    "            id_atom =  int(atoms[j][0])-1\n",
    "            data_array_x[i,id_atom] = atoms[j][columns[0]]\n",
    "            data_array_y[i,id_atom] = atoms[j][columns[1]]\n",
    "\n",
    "\n",
    "    toadd = 0\n",
    "    for kn in range(28):\n",
    "\n",
    "        xlist = np.array([data_array_x[:,i-1].tolist() for i in range(1+kn*7,8+kn*7)]).T\n",
    "        ylist = np.array([data_array_y[:,i-1].tolist() for i in range(1+kn*7,8+kn*7)]).T\n",
    "        frame_pos_list = [[[data_array_x[j,i-1],data_array_y[j,i-1]] for j in range(data_array_x.shape[0])] for i in range(1+kn*7,8+kn*7)] \n",
    "\n",
    "       \n",
    "\n",
    "        oneD_list = []\n",
    "        if kn%2==0 and kn>0:\n",
    "            toadd +=2.5\n",
    "\n",
    "        for frame in range(len(frame_pos_list[0])):\n",
    "\n",
    "            pos_frame = [frame_pos_list[i][frame] for i in range(len(frame_pos_list)) ] \n",
    "\n",
    "            pos_frame_x = [pos_frame[k][0]-pos_frame[0][0]  for k in range(len(pos_frame))]\n",
    "            pos_frame_y = [pos_frame[k][1]-pos_frame[0][1]  for k in range(len(pos_frame))]\n",
    "\n",
    "            theta = math.atan2(pos_frame_y[1], pos_frame_x[1])\n",
    "            c, s = np.cos(-theta), np.sin(-theta)\n",
    "            R = np.array(((c, -s), (s, c)))\n",
    "            pos_array = [ np.dot(R,np.array([x,y])) for x,y in zip(pos_frame_x,pos_frame_y) ] \n",
    "\n",
    "            pos_frame_x = np.array([v[0] for v in pos_array ])\n",
    "            pos_frame_y = np.array([v[1]  for v in pos_array ])\n",
    "\n",
    "            val = pca.transform( np.concatenate((pos_frame_x[0:5],  pos_frame_y[0:5])).reshape(1, -1)  )\n",
    "            oneD_list.append(val[0][0]+toadd)\n",
    "        \n",
    "        all_signal.append(oneD_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "plt.plot(all_signal[2*i], c='r')\n",
    "plt.plot(all_signal[2*i+1], c='g')\n",
    "plt.savefig(f'./figure/special_telegraph{5.000000000000001e-04}.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot NEB energy (fig 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_reaction_coordinate_function(database, keys, nb_int, nb_out, isplot = False):\n",
    "    _NEB_HP_atom_list_list = database.db_pairs[keys[0]][keys[1]]['sols'][keys[2]]['NEB_HP_atom_list_list']\n",
    "    _NEB_HP_PP_atom_list_list = database.db_pairs[keys[0]][keys[1]]['sols'][keys[2]]['NEB_HP_PP_atom_list_list']\n",
    "\n",
    "\n",
    "    pos_list = get_neb_pos_list(_NEB_HP_atom_list_list)\n",
    "    path_h_x = pos_list[:,0:nb_out]\n",
    "    path_h_y = pos_list[:,nb_out+nb_int:2*nb_out+nb_int]\n",
    "    path_h = np.concatenate((path_h_x, path_h_y), axis=1)\n",
    "    #get the pca\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(path_h)\n",
    "    #fit the data and get the grid for the plot\n",
    "\n",
    "    def func_translate(to_translate): \n",
    "\n",
    "\n",
    "        \n",
    "        pos_list = get_neb_pos_list(to_translate)\n",
    "        path_h_x = pos_list[:,0:nb_out]\n",
    "        path_h_y = pos_list[:,nb_out+nb_int:2*nb_out+nb_int]\n",
    "        path_h = np.concatenate((path_h_x, path_h_y), axis=1)\n",
    "        return pca.transform(path_h)\n",
    "\n",
    "    pca_data = func_translate(_NEB_HP_atom_list_list)\n",
    "    endpoint_pca = [pca_data[0], pca_data[-1]]\n",
    "\n",
    "    trans_func_test = get_translation_binded_function_neb(database, keys[0], keys[1], keys[2])\n",
    "\n",
    "    def func_translate_binded(to_translate):\n",
    "        list_pos_bottom, list_pos_top = trans_func_test(to_translate)\n",
    "        pos_list_bind = get_neb_pos_list(list_pos_bottom)\n",
    "        index_pca_binded=list(range(0,nb_out))\n",
    "        path_bind_x = np.take(pos_list_bind,index_pca_binded,1)\n",
    "        path_bind_y = np.take(pos_list_bind, [nb_out+nb_int+v for v in index_pca_binded],1)\n",
    "        path_bind = np.concatenate((path_bind_x, path_bind_y), axis=1)\n",
    "        return pca.transform(path_bind)\n",
    "        \n",
    "\n",
    "    pca_data_bind = func_translate_binded(_NEB_HP_PP_atom_list_list)\n",
    "    endpoint_pca_bind = [pca_data_bind[0], pca_data_bind[-1]]\n",
    "\n",
    "    if isplot:\n",
    "        plt.plot([v[0] for v in pca_data], [v[1] for v in pca_data],  'o')\n",
    "        plt.plot([v[0] for v in pca_data_bind], [v[1] for v in pca_data_bind],  'o')\n",
    "    return  (func_translate, func_translate_binded), (endpoint_pca, endpoint_pca_bind)\n",
    "\n",
    "\n",
    "key_h, key_p, key_s = keys\n",
    "binded_energy = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_PP_energy']\n",
    "plt.plot([i/(len(energy_list_binded)-1) for i in range(len(energy_list_binded))], energy_list_binded,'o', label=\"bound\")\n",
    "energy = db.db_pairs[key_h][key_p]['sols'][key_s]['NEB_HP_energy']\n",
    "plt.plot([i/(len(vec_out[1])-1) for i in range(len(vec_out[1]))], vec_out[1],'o', label=\"separated\")\n",
    "plt.legend()\n",
    "plt.savefig(f'./figure/reaction_path_{keys[0]}_{keys[1]}_{keys[2]}_{sum(pca.explained_variance_ratio_)}.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
